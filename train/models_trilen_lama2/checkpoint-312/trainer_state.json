{
  "best_metric": 1.3980482816696167,
  "best_model_checkpoint": "/public/home/xiangyuduan/lyt/bad_word/train/models_trilen_lama2/checkpoint-200",
  "epoch": 0.9984,
  "eval_steps": 200,
  "global_step": 312,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0032,
      "grad_norm": 0.23176166415214539,
      "learning_rate": 9.999746529806349e-05,
      "loss": 1.8238,
      "step": 1
    },
    {
      "epoch": 0.0064,
      "grad_norm": 0.29615166783332825,
      "learning_rate": 9.998986144924251e-05,
      "loss": 1.9036,
      "step": 2
    },
    {
      "epoch": 0.0096,
      "grad_norm": 0.3764164447784424,
      "learning_rate": 9.997718922447667e-05,
      "loss": 1.8203,
      "step": 3
    },
    {
      "epoch": 0.0128,
      "grad_norm": 0.4297853410243988,
      "learning_rate": 9.995944990857849e-05,
      "loss": 1.8272,
      "step": 4
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.5372052192687988,
      "learning_rate": 9.993664530010308e-05,
      "loss": 1.7498,
      "step": 5
    },
    {
      "epoch": 0.0192,
      "grad_norm": 0.5022000074386597,
      "learning_rate": 9.990877771116589e-05,
      "loss": 1.6524,
      "step": 6
    },
    {
      "epoch": 0.0224,
      "grad_norm": 0.6281750798225403,
      "learning_rate": 9.987584996720814e-05,
      "loss": 1.6668,
      "step": 7
    },
    {
      "epoch": 0.0256,
      "grad_norm": 0.5880664587020874,
      "learning_rate": 9.983786540671051e-05,
      "loss": 1.6539,
      "step": 8
    },
    {
      "epoch": 0.0288,
      "grad_norm": 0.5002825260162354,
      "learning_rate": 9.979482788085454e-05,
      "loss": 1.6862,
      "step": 9
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.505189061164856,
      "learning_rate": 9.974674175313228e-05,
      "loss": 1.6022,
      "step": 10
    },
    {
      "epoch": 0.0352,
      "grad_norm": 0.5211021900177002,
      "learning_rate": 9.969361189890373e-05,
      "loss": 1.615,
      "step": 11
    },
    {
      "epoch": 0.0384,
      "grad_norm": 0.5934424996376038,
      "learning_rate": 9.96354437049027e-05,
      "loss": 1.6177,
      "step": 12
    },
    {
      "epoch": 0.0416,
      "grad_norm": 0.7363110780715942,
      "learning_rate": 9.957224306869053e-05,
      "loss": 1.5267,
      "step": 13
    },
    {
      "epoch": 0.0448,
      "grad_norm": 0.5944032669067383,
      "learning_rate": 9.95040163980582e-05,
      "loss": 1.4924,
      "step": 14
    },
    {
      "epoch": 0.048,
      "grad_norm": 0.31724369525909424,
      "learning_rate": 9.943077061037671e-05,
      "loss": 1.5535,
      "step": 15
    },
    {
      "epoch": 0.0512,
      "grad_norm": 0.18770770728588104,
      "learning_rate": 9.935251313189564e-05,
      "loss": 1.5081,
      "step": 16
    },
    {
      "epoch": 0.0544,
      "grad_norm": 0.17747336626052856,
      "learning_rate": 9.92692518969903e-05,
      "loss": 1.5874,
      "step": 17
    },
    {
      "epoch": 0.0576,
      "grad_norm": 0.15818339586257935,
      "learning_rate": 9.918099534735718e-05,
      "loss": 1.5211,
      "step": 18
    },
    {
      "epoch": 0.0608,
      "grad_norm": 0.15931344032287598,
      "learning_rate": 9.908775243115821e-05,
      "loss": 1.4709,
      "step": 19
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.1782822608947754,
      "learning_rate": 9.898953260211338e-05,
      "loss": 1.5315,
      "step": 20
    },
    {
      "epoch": 0.0672,
      "grad_norm": 0.14828629791736603,
      "learning_rate": 9.888634581854234e-05,
      "loss": 1.5498,
      "step": 21
    },
    {
      "epoch": 0.0704,
      "grad_norm": 0.17471152544021606,
      "learning_rate": 9.877820254235471e-05,
      "loss": 1.496,
      "step": 22
    },
    {
      "epoch": 0.0736,
      "grad_norm": 0.13924069702625275,
      "learning_rate": 9.86651137379893e-05,
      "loss": 1.5492,
      "step": 23
    },
    {
      "epoch": 0.0768,
      "grad_norm": 0.14384561777114868,
      "learning_rate": 9.85470908713026e-05,
      "loss": 1.5799,
      "step": 24
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.15495362877845764,
      "learning_rate": 9.842414590840617e-05,
      "loss": 1.4783,
      "step": 25
    },
    {
      "epoch": 0.0832,
      "grad_norm": 0.14443421363830566,
      "learning_rate": 9.829629131445342e-05,
      "loss": 1.567,
      "step": 26
    },
    {
      "epoch": 0.0864,
      "grad_norm": 0.15826839208602905,
      "learning_rate": 9.816354005237583e-05,
      "loss": 1.5726,
      "step": 27
    },
    {
      "epoch": 0.0896,
      "grad_norm": 0.15111730992794037,
      "learning_rate": 9.802590558156862e-05,
      "loss": 1.5265,
      "step": 28
    },
    {
      "epoch": 0.0928,
      "grad_norm": 0.15073926746845245,
      "learning_rate": 9.78834018565262e-05,
      "loss": 1.5541,
      "step": 29
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.15154077112674713,
      "learning_rate": 9.773604332542729e-05,
      "loss": 1.5273,
      "step": 30
    },
    {
      "epoch": 0.0992,
      "grad_norm": 0.15297161042690277,
      "learning_rate": 9.758384492867003e-05,
      "loss": 1.5457,
      "step": 31
    },
    {
      "epoch": 0.1024,
      "grad_norm": 0.16372254490852356,
      "learning_rate": 9.742682209735727e-05,
      "loss": 1.4774,
      "step": 32
    },
    {
      "epoch": 0.1056,
      "grad_norm": 0.15120740234851837,
      "learning_rate": 9.726499075173201e-05,
      "loss": 1.5172,
      "step": 33
    },
    {
      "epoch": 0.1088,
      "grad_norm": 0.15128256380558014,
      "learning_rate": 9.709836729956325e-05,
      "loss": 1.5303,
      "step": 34
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.17014062404632568,
      "learning_rate": 9.692696863448245e-05,
      "loss": 1.4837,
      "step": 35
    },
    {
      "epoch": 0.1152,
      "grad_norm": 0.1495407521724701,
      "learning_rate": 9.675081213427076e-05,
      "loss": 1.47,
      "step": 36
    },
    {
      "epoch": 0.1184,
      "grad_norm": 0.155279740691185,
      "learning_rate": 9.656991565909704e-05,
      "loss": 1.4548,
      "step": 37
    },
    {
      "epoch": 0.1216,
      "grad_norm": 0.15490874648094177,
      "learning_rate": 9.638429754970715e-05,
      "loss": 1.4466,
      "step": 38
    },
    {
      "epoch": 0.1248,
      "grad_norm": 0.17144306004047394,
      "learning_rate": 9.619397662556435e-05,
      "loss": 1.5663,
      "step": 39
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.1672700047492981,
      "learning_rate": 9.599897218294122e-05,
      "loss": 1.5299,
      "step": 40
    },
    {
      "epoch": 0.1312,
      "grad_norm": 0.17107032239437103,
      "learning_rate": 9.579930399296331e-05,
      "loss": 1.5217,
      "step": 41
    },
    {
      "epoch": 0.1344,
      "grad_norm": 0.15937089920043945,
      "learning_rate": 9.559499229960451e-05,
      "loss": 1.448,
      "step": 42
    },
    {
      "epoch": 0.1376,
      "grad_norm": 0.18131671845912933,
      "learning_rate": 9.538605781763463e-05,
      "loss": 1.4872,
      "step": 43
    },
    {
      "epoch": 0.1408,
      "grad_norm": 0.16479146480560303,
      "learning_rate": 9.517252173051911e-05,
      "loss": 1.497,
      "step": 44
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.17762410640716553,
      "learning_rate": 9.495440568827129e-05,
      "loss": 1.4487,
      "step": 45
    },
    {
      "epoch": 0.1472,
      "grad_norm": 0.17930614948272705,
      "learning_rate": 9.473173180525737e-05,
      "loss": 1.51,
      "step": 46
    },
    {
      "epoch": 0.1504,
      "grad_norm": 0.16829872131347656,
      "learning_rate": 9.450452265795423e-05,
      "loss": 1.5301,
      "step": 47
    },
    {
      "epoch": 0.1536,
      "grad_norm": 0.1676996648311615,
      "learning_rate": 9.42728012826605e-05,
      "loss": 1.4422,
      "step": 48
    },
    {
      "epoch": 0.1568,
      "grad_norm": 0.1638401597738266,
      "learning_rate": 9.403659117316093e-05,
      "loss": 1.4817,
      "step": 49
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.18554311990737915,
      "learning_rate": 9.37959162783444e-05,
      "loss": 1.5726,
      "step": 50
    },
    {
      "epoch": 0.1632,
      "grad_norm": 0.1705474704504013,
      "learning_rate": 9.355080099977578e-05,
      "loss": 1.5223,
      "step": 51
    },
    {
      "epoch": 0.1664,
      "grad_norm": 0.18135592341423035,
      "learning_rate": 9.330127018922194e-05,
      "loss": 1.4748,
      "step": 52
    },
    {
      "epoch": 0.1696,
      "grad_norm": 0.1820274442434311,
      "learning_rate": 9.3047349146132e-05,
      "loss": 1.5483,
      "step": 53
    },
    {
      "epoch": 0.1728,
      "grad_norm": 0.1737987995147705,
      "learning_rate": 9.278906361507238e-05,
      "loss": 1.5121,
      "step": 54
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.18892166018486023,
      "learning_rate": 9.252643978311649e-05,
      "loss": 1.5807,
      "step": 55
    },
    {
      "epoch": 0.1792,
      "grad_norm": 0.18028207123279572,
      "learning_rate": 9.225950427718975e-05,
      "loss": 1.567,
      "step": 56
    },
    {
      "epoch": 0.1824,
      "grad_norm": 0.1738777756690979,
      "learning_rate": 9.19882841613699e-05,
      "loss": 1.5705,
      "step": 57
    },
    {
      "epoch": 0.1856,
      "grad_norm": 0.17126227915287018,
      "learning_rate": 9.171280693414307e-05,
      "loss": 1.4853,
      "step": 58
    },
    {
      "epoch": 0.1888,
      "grad_norm": 0.17681652307510376,
      "learning_rate": 9.143310052561571e-05,
      "loss": 1.416,
      "step": 59
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.17886364459991455,
      "learning_rate": 9.114919329468282e-05,
      "loss": 1.5112,
      "step": 60
    },
    {
      "epoch": 0.1952,
      "grad_norm": 0.17502084374427795,
      "learning_rate": 9.086111402615273e-05,
      "loss": 1.4809,
      "step": 61
    },
    {
      "epoch": 0.1984,
      "grad_norm": 0.1820375919342041,
      "learning_rate": 9.056889192782866e-05,
      "loss": 1.5119,
      "step": 62
    },
    {
      "epoch": 0.2016,
      "grad_norm": 0.18186968564987183,
      "learning_rate": 9.02725566275473e-05,
      "loss": 1.515,
      "step": 63
    },
    {
      "epoch": 0.2048,
      "grad_norm": 0.19284865260124207,
      "learning_rate": 8.997213817017507e-05,
      "loss": 1.4446,
      "step": 64
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.17723782360553741,
      "learning_rate": 8.966766701456177e-05,
      "loss": 1.4825,
      "step": 65
    },
    {
      "epoch": 0.2112,
      "grad_norm": 0.17772173881530762,
      "learning_rate": 8.935917403045251e-05,
      "loss": 1.4772,
      "step": 66
    },
    {
      "epoch": 0.2144,
      "grad_norm": 0.16505166888237,
      "learning_rate": 8.904669049535789e-05,
      "loss": 1.4459,
      "step": 67
    },
    {
      "epoch": 0.2176,
      "grad_norm": 0.1844703108072281,
      "learning_rate": 8.873024809138272e-05,
      "loss": 1.4963,
      "step": 68
    },
    {
      "epoch": 0.2208,
      "grad_norm": 0.18417468667030334,
      "learning_rate": 8.840987890201403e-05,
      "loss": 1.491,
      "step": 69
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.2004726678133011,
      "learning_rate": 8.808561540886796e-05,
      "loss": 1.5766,
      "step": 70
    },
    {
      "epoch": 0.2272,
      "grad_norm": 0.19853445887565613,
      "learning_rate": 8.775749048839669e-05,
      "loss": 1.5194,
      "step": 71
    },
    {
      "epoch": 0.2304,
      "grad_norm": 0.1846824586391449,
      "learning_rate": 8.742553740855506e-05,
      "loss": 1.5693,
      "step": 72
    },
    {
      "epoch": 0.2336,
      "grad_norm": 0.19963587820529938,
      "learning_rate": 8.708978982542765e-05,
      "loss": 1.5682,
      "step": 73
    },
    {
      "epoch": 0.2368,
      "grad_norm": 0.2170238196849823,
      "learning_rate": 8.675028177981643e-05,
      "loss": 1.5434,
      "step": 74
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.20762839913368225,
      "learning_rate": 8.640704769378942e-05,
      "loss": 1.4848,
      "step": 75
    },
    {
      "epoch": 0.2432,
      "grad_norm": 0.2134760618209839,
      "learning_rate": 8.606012236719073e-05,
      "loss": 1.5218,
      "step": 76
    },
    {
      "epoch": 0.2464,
      "grad_norm": 0.18470242619514465,
      "learning_rate": 8.570954097411223e-05,
      "loss": 1.5369,
      "step": 77
    },
    {
      "epoch": 0.2496,
      "grad_norm": 0.18466021120548248,
      "learning_rate": 8.535533905932738e-05,
      "loss": 1.4588,
      "step": 78
    },
    {
      "epoch": 0.2528,
      "grad_norm": 0.2150765061378479,
      "learning_rate": 8.499755253468733e-05,
      "loss": 1.5093,
      "step": 79
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.2056579440832138,
      "learning_rate": 8.463621767547998e-05,
      "loss": 1.4727,
      "step": 80
    },
    {
      "epoch": 0.2592,
      "grad_norm": 0.20265470445156097,
      "learning_rate": 8.427137111675199e-05,
      "loss": 1.4616,
      "step": 81
    },
    {
      "epoch": 0.2624,
      "grad_norm": 0.21444979310035706,
      "learning_rate": 8.390304984959454e-05,
      "loss": 1.5572,
      "step": 82
    },
    {
      "epoch": 0.2656,
      "grad_norm": 0.22518803179264069,
      "learning_rate": 8.353129121739281e-05,
      "loss": 1.494,
      "step": 83
    },
    {
      "epoch": 0.2688,
      "grad_norm": 0.1991700828075409,
      "learning_rate": 8.315613291203976e-05,
      "loss": 1.5044,
      "step": 84
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.18783816695213318,
      "learning_rate": 8.277761297011475e-05,
      "loss": 1.5111,
      "step": 85
    },
    {
      "epoch": 0.2752,
      "grad_norm": 0.19349966943264008,
      "learning_rate": 8.239576976902695e-05,
      "loss": 1.4641,
      "step": 86
    },
    {
      "epoch": 0.2784,
      "grad_norm": 0.20741330087184906,
      "learning_rate": 8.201064202312441e-05,
      "loss": 1.4336,
      "step": 87
    },
    {
      "epoch": 0.2816,
      "grad_norm": 0.22306475043296814,
      "learning_rate": 8.162226877976887e-05,
      "loss": 1.4328,
      "step": 88
    },
    {
      "epoch": 0.2848,
      "grad_norm": 0.20375435054302216,
      "learning_rate": 8.123068941537682e-05,
      "loss": 1.5377,
      "step": 89
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.19599342346191406,
      "learning_rate": 8.083594363142717e-05,
      "loss": 1.4322,
      "step": 90
    },
    {
      "epoch": 0.2912,
      "grad_norm": 0.20990800857543945,
      "learning_rate": 8.043807145043604e-05,
      "loss": 1.4977,
      "step": 91
    },
    {
      "epoch": 0.2944,
      "grad_norm": 0.22354339063167572,
      "learning_rate": 8.003711321189895e-05,
      "loss": 1.4425,
      "step": 92
    },
    {
      "epoch": 0.2976,
      "grad_norm": 0.2117813676595688,
      "learning_rate": 7.963310956820085e-05,
      "loss": 1.4878,
      "step": 93
    },
    {
      "epoch": 0.3008,
      "grad_norm": 0.19523502886295319,
      "learning_rate": 7.922610148049445e-05,
      "loss": 1.5085,
      "step": 94
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.193766787648201,
      "learning_rate": 7.881613021454727e-05,
      "loss": 1.3792,
      "step": 95
    },
    {
      "epoch": 0.3072,
      "grad_norm": 0.20720484852790833,
      "learning_rate": 7.840323733655778e-05,
      "loss": 1.4586,
      "step": 96
    },
    {
      "epoch": 0.3104,
      "grad_norm": 0.22450633347034454,
      "learning_rate": 7.798746470894111e-05,
      "loss": 1.4693,
      "step": 97
    },
    {
      "epoch": 0.3136,
      "grad_norm": 0.21798844635486603,
      "learning_rate": 7.756885448608459e-05,
      "loss": 1.5468,
      "step": 98
    },
    {
      "epoch": 0.3168,
      "grad_norm": 0.1973116099834442,
      "learning_rate": 7.714744911007394e-05,
      "loss": 1.49,
      "step": 99
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.2273067981004715,
      "learning_rate": 7.672329130639005e-05,
      "loss": 1.5389,
      "step": 100
    },
    {
      "epoch": 0.3232,
      "grad_norm": 0.2080739438533783,
      "learning_rate": 7.62964240795772e-05,
      "loss": 1.4266,
      "step": 101
    },
    {
      "epoch": 0.3264,
      "grad_norm": 0.2225743979215622,
      "learning_rate": 7.586689070888284e-05,
      "loss": 1.5351,
      "step": 102
    },
    {
      "epoch": 0.3296,
      "grad_norm": 0.20242030918598175,
      "learning_rate": 7.543473474386961e-05,
      "loss": 1.3964,
      "step": 103
    },
    {
      "epoch": 0.3328,
      "grad_norm": 0.21564264595508575,
      "learning_rate": 7.500000000000001e-05,
      "loss": 1.4505,
      "step": 104
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.206800639629364,
      "learning_rate": 7.456273055419388e-05,
      "loss": 1.4646,
      "step": 105
    },
    {
      "epoch": 0.3392,
      "grad_norm": 0.2250158041715622,
      "learning_rate": 7.412297074035967e-05,
      "loss": 1.5055,
      "step": 106
    },
    {
      "epoch": 0.3424,
      "grad_norm": 0.21213899552822113,
      "learning_rate": 7.368076514489947e-05,
      "loss": 1.4207,
      "step": 107
    },
    {
      "epoch": 0.3456,
      "grad_norm": 0.20693133771419525,
      "learning_rate": 7.323615860218843e-05,
      "loss": 1.4205,
      "step": 108
    },
    {
      "epoch": 0.3488,
      "grad_norm": 0.21451511979103088,
      "learning_rate": 7.278919619002916e-05,
      "loss": 1.4644,
      "step": 109
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.21830488741397858,
      "learning_rate": 7.233992322508129e-05,
      "loss": 1.4939,
      "step": 110
    },
    {
      "epoch": 0.3552,
      "grad_norm": 0.22071906924247742,
      "learning_rate": 7.188838525826702e-05,
      "loss": 1.3789,
      "step": 111
    },
    {
      "epoch": 0.3584,
      "grad_norm": 0.23402822017669678,
      "learning_rate": 7.143462807015271e-05,
      "loss": 1.4782,
      "step": 112
    },
    {
      "epoch": 0.3616,
      "grad_norm": 0.21054179966449738,
      "learning_rate": 7.097869766630729e-05,
      "loss": 1.4724,
      "step": 113
    },
    {
      "epoch": 0.3648,
      "grad_norm": 0.21824075281620026,
      "learning_rate": 7.052064027263786e-05,
      "loss": 1.5,
      "step": 114
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.2328924685716629,
      "learning_rate": 7.006050233070289e-05,
      "loss": 1.4556,
      "step": 115
    },
    {
      "epoch": 0.3712,
      "grad_norm": 0.21815703809261322,
      "learning_rate": 6.959833049300377e-05,
      "loss": 1.4942,
      "step": 116
    },
    {
      "epoch": 0.3744,
      "grad_norm": 0.220895916223526,
      "learning_rate": 6.91341716182545e-05,
      "loss": 1.5372,
      "step": 117
    },
    {
      "epoch": 0.3776,
      "grad_norm": 0.2225724309682846,
      "learning_rate": 6.866807276663106e-05,
      "loss": 1.462,
      "step": 118
    },
    {
      "epoch": 0.3808,
      "grad_norm": 0.21582326292991638,
      "learning_rate": 6.820008119499992e-05,
      "loss": 1.4491,
      "step": 119
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.23293077945709229,
      "learning_rate": 6.773024435212678e-05,
      "loss": 1.4707,
      "step": 120
    },
    {
      "epoch": 0.3872,
      "grad_norm": 0.225950226187706,
      "learning_rate": 6.72586098738659e-05,
      "loss": 1.4794,
      "step": 121
    },
    {
      "epoch": 0.3904,
      "grad_norm": 0.22834767401218414,
      "learning_rate": 6.678522557833024e-05,
      "loss": 1.4884,
      "step": 122
    },
    {
      "epoch": 0.3936,
      "grad_norm": 0.20669648051261902,
      "learning_rate": 6.631013946104347e-05,
      "loss": 1.4765,
      "step": 123
    },
    {
      "epoch": 0.3968,
      "grad_norm": 0.23323366045951843,
      "learning_rate": 6.583339969007363e-05,
      "loss": 1.4952,
      "step": 124
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.2130453884601593,
      "learning_rate": 6.535505460114954e-05,
      "loss": 1.4285,
      "step": 125
    },
    {
      "epoch": 0.4032,
      "grad_norm": 0.2486802637577057,
      "learning_rate": 6.487515269276016e-05,
      "loss": 1.4993,
      "step": 126
    },
    {
      "epoch": 0.4064,
      "grad_norm": 0.217650905251503,
      "learning_rate": 6.439374262123731e-05,
      "loss": 1.3475,
      "step": 127
    },
    {
      "epoch": 0.4096,
      "grad_norm": 0.20938394963741302,
      "learning_rate": 6.391087319582264e-05,
      "loss": 1.5049,
      "step": 128
    },
    {
      "epoch": 0.4128,
      "grad_norm": 0.22769208252429962,
      "learning_rate": 6.342659337371885e-05,
      "loss": 1.4436,
      "step": 129
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.23153243958950043,
      "learning_rate": 6.294095225512603e-05,
      "loss": 1.5514,
      "step": 130
    },
    {
      "epoch": 0.4192,
      "grad_norm": 0.23232996463775635,
      "learning_rate": 6.24539990782636e-05,
      "loss": 1.4419,
      "step": 131
    },
    {
      "epoch": 0.4224,
      "grad_norm": 0.2191871702671051,
      "learning_rate": 6.19657832143779e-05,
      "loss": 1.4475,
      "step": 132
    },
    {
      "epoch": 0.4256,
      "grad_norm": 0.23030366003513336,
      "learning_rate": 6.147635416273678e-05,
      "loss": 1.4299,
      "step": 133
    },
    {
      "epoch": 0.4288,
      "grad_norm": 0.23760047554969788,
      "learning_rate": 6.098576154561087e-05,
      "loss": 1.4558,
      "step": 134
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.23353542387485504,
      "learning_rate": 6.049405510324238e-05,
      "loss": 1.4053,
      "step": 135
    },
    {
      "epoch": 0.4352,
      "grad_norm": 0.24377356469631195,
      "learning_rate": 6.0001284688802226e-05,
      "loss": 1.4562,
      "step": 136
    },
    {
      "epoch": 0.4384,
      "grad_norm": 0.2320256531238556,
      "learning_rate": 5.950750026333534e-05,
      "loss": 1.5022,
      "step": 137
    },
    {
      "epoch": 0.4416,
      "grad_norm": 0.20699360966682434,
      "learning_rate": 5.90127518906953e-05,
      "loss": 1.4323,
      "step": 138
    },
    {
      "epoch": 0.4448,
      "grad_norm": 0.22947773337364197,
      "learning_rate": 5.851708973246841e-05,
      "loss": 1.4802,
      "step": 139
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.23925213515758514,
      "learning_rate": 5.8020564042888015e-05,
      "loss": 1.4487,
      "step": 140
    },
    {
      "epoch": 0.4512,
      "grad_norm": 0.24451415240764618,
      "learning_rate": 5.752322516373916e-05,
      "loss": 1.4201,
      "step": 141
    },
    {
      "epoch": 0.4544,
      "grad_norm": 0.22944024205207825,
      "learning_rate": 5.702512351925464e-05,
      "loss": 1.4045,
      "step": 142
    },
    {
      "epoch": 0.4576,
      "grad_norm": 0.24237781763076782,
      "learning_rate": 5.6526309611002594e-05,
      "loss": 1.5379,
      "step": 143
    },
    {
      "epoch": 0.4608,
      "grad_norm": 0.21249224245548248,
      "learning_rate": 5.602683401276615e-05,
      "loss": 1.426,
      "step": 144
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.2391541451215744,
      "learning_rate": 5.5526747365416e-05,
      "loss": 1.4898,
      "step": 145
    },
    {
      "epoch": 0.4672,
      "grad_norm": 0.23022063076496124,
      "learning_rate": 5.502610037177586e-05,
      "loss": 1.4178,
      "step": 146
    },
    {
      "epoch": 0.4704,
      "grad_norm": 0.23546047508716583,
      "learning_rate": 5.45249437914819e-05,
      "loss": 1.4652,
      "step": 147
    },
    {
      "epoch": 0.4736,
      "grad_norm": 0.2318134605884552,
      "learning_rate": 5.402332843583631e-05,
      "loss": 1.5049,
      "step": 148
    },
    {
      "epoch": 0.4768,
      "grad_norm": 0.22403506934642792,
      "learning_rate": 5.35213051626556e-05,
      "loss": 1.4092,
      "step": 149
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.2390652894973755,
      "learning_rate": 5.3018924871114305e-05,
      "loss": 1.4954,
      "step": 150
    },
    {
      "epoch": 0.4832,
      "grad_norm": 0.2489471584558487,
      "learning_rate": 5.2516238496584335e-05,
      "loss": 1.4521,
      "step": 151
    },
    {
      "epoch": 0.4864,
      "grad_norm": 0.22936032712459564,
      "learning_rate": 5.201329700547076e-05,
      "loss": 1.4241,
      "step": 152
    },
    {
      "epoch": 0.4896,
      "grad_norm": 0.2487250417470932,
      "learning_rate": 5.151015139004445e-05,
      "loss": 1.4359,
      "step": 153
    },
    {
      "epoch": 0.4928,
      "grad_norm": 0.2505354881286621,
      "learning_rate": 5.100685266327202e-05,
      "loss": 1.4421,
      "step": 154
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.251007616519928,
      "learning_rate": 5.0503451853643776e-05,
      "loss": 1.4979,
      "step": 155
    },
    {
      "epoch": 0.4992,
      "grad_norm": 0.2737797200679779,
      "learning_rate": 5e-05,
      "loss": 1.4489,
      "step": 156
    },
    {
      "epoch": 0.5024,
      "grad_norm": 0.2377866953611374,
      "learning_rate": 4.949654814635623e-05,
      "loss": 1.4795,
      "step": 157
    },
    {
      "epoch": 0.5056,
      "grad_norm": 0.2359086573123932,
      "learning_rate": 4.899314733672799e-05,
      "loss": 1.4271,
      "step": 158
    },
    {
      "epoch": 0.5088,
      "grad_norm": 0.22409771382808685,
      "learning_rate": 4.848984860995557e-05,
      "loss": 1.3869,
      "step": 159
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.2342718243598938,
      "learning_rate": 4.798670299452926e-05,
      "loss": 1.4416,
      "step": 160
    },
    {
      "epoch": 0.5152,
      "grad_norm": 0.25043386220932007,
      "learning_rate": 4.748376150341566e-05,
      "loss": 1.5038,
      "step": 161
    },
    {
      "epoch": 0.5184,
      "grad_norm": 0.25634440779685974,
      "learning_rate": 4.6981075128885693e-05,
      "loss": 1.4465,
      "step": 162
    },
    {
      "epoch": 0.5216,
      "grad_norm": 0.22238898277282715,
      "learning_rate": 4.6478694837344404e-05,
      "loss": 1.4768,
      "step": 163
    },
    {
      "epoch": 0.5248,
      "grad_norm": 0.24005860090255737,
      "learning_rate": 4.597667156416371e-05,
      "loss": 1.4383,
      "step": 164
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.2437599003314972,
      "learning_rate": 4.547505620851811e-05,
      "loss": 1.454,
      "step": 165
    },
    {
      "epoch": 0.5312,
      "grad_norm": 0.23644286394119263,
      "learning_rate": 4.4973899628224154e-05,
      "loss": 1.4514,
      "step": 166
    },
    {
      "epoch": 0.5344,
      "grad_norm": 0.24286046624183655,
      "learning_rate": 4.4473252634584015e-05,
      "loss": 1.4603,
      "step": 167
    },
    {
      "epoch": 0.5376,
      "grad_norm": 0.23443783819675446,
      "learning_rate": 4.397316598723385e-05,
      "loss": 1.4517,
      "step": 168
    },
    {
      "epoch": 0.5408,
      "grad_norm": 0.22693750262260437,
      "learning_rate": 4.347369038899744e-05,
      "loss": 1.4298,
      "step": 169
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.26583942770957947,
      "learning_rate": 4.297487648074538e-05,
      "loss": 1.4686,
      "step": 170
    },
    {
      "epoch": 0.5472,
      "grad_norm": 0.2476925551891327,
      "learning_rate": 4.2476774836260845e-05,
      "loss": 1.429,
      "step": 171
    },
    {
      "epoch": 0.5504,
      "grad_norm": 0.24961483478546143,
      "learning_rate": 4.197943595711198e-05,
      "loss": 1.4847,
      "step": 172
    },
    {
      "epoch": 0.5536,
      "grad_norm": 0.2541221082210541,
      "learning_rate": 4.1482910267531585e-05,
      "loss": 1.4348,
      "step": 173
    },
    {
      "epoch": 0.5568,
      "grad_norm": 0.26728755235671997,
      "learning_rate": 4.0987248109304714e-05,
      "loss": 1.4082,
      "step": 174
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.25326186418533325,
      "learning_rate": 4.049249973666467e-05,
      "loss": 1.4794,
      "step": 175
    },
    {
      "epoch": 0.5632,
      "grad_norm": 0.2432759404182434,
      "learning_rate": 3.9998715311197785e-05,
      "loss": 1.5036,
      "step": 176
    },
    {
      "epoch": 0.5664,
      "grad_norm": 0.26458504796028137,
      "learning_rate": 3.950594489675763e-05,
      "loss": 1.4417,
      "step": 177
    },
    {
      "epoch": 0.5696,
      "grad_norm": 0.26542192697525024,
      "learning_rate": 3.901423845438916e-05,
      "loss": 1.5592,
      "step": 178
    },
    {
      "epoch": 0.5728,
      "grad_norm": 0.2649816572666168,
      "learning_rate": 3.852364583726324e-05,
      "loss": 1.4027,
      "step": 179
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.24011816084384918,
      "learning_rate": 3.803421678562213e-05,
      "loss": 1.3708,
      "step": 180
    },
    {
      "epoch": 0.5792,
      "grad_norm": 0.25622645020484924,
      "learning_rate": 3.754600092173641e-05,
      "loss": 1.435,
      "step": 181
    },
    {
      "epoch": 0.5824,
      "grad_norm": 0.2523292005062103,
      "learning_rate": 3.705904774487396e-05,
      "loss": 1.4763,
      "step": 182
    },
    {
      "epoch": 0.5856,
      "grad_norm": 0.2495742291212082,
      "learning_rate": 3.657340662628116e-05,
      "loss": 1.4099,
      "step": 183
    },
    {
      "epoch": 0.5888,
      "grad_norm": 0.25028860569000244,
      "learning_rate": 3.608912680417737e-05,
      "loss": 1.3851,
      "step": 184
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.2539878189563751,
      "learning_rate": 3.5606257378762696e-05,
      "loss": 1.4901,
      "step": 185
    },
    {
      "epoch": 0.5952,
      "grad_norm": 0.2600911557674408,
      "learning_rate": 3.512484730723986e-05,
      "loss": 1.4255,
      "step": 186
    },
    {
      "epoch": 0.5984,
      "grad_norm": 0.26837408542633057,
      "learning_rate": 3.464494539885047e-05,
      "loss": 1.4253,
      "step": 187
    },
    {
      "epoch": 0.6016,
      "grad_norm": 0.24634462594985962,
      "learning_rate": 3.4166600309926387e-05,
      "loss": 1.5379,
      "step": 188
    },
    {
      "epoch": 0.6048,
      "grad_norm": 0.27501747012138367,
      "learning_rate": 3.368986053895655e-05,
      "loss": 1.506,
      "step": 189
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.24988609552383423,
      "learning_rate": 3.3214774421669774e-05,
      "loss": 1.368,
      "step": 190
    },
    {
      "epoch": 0.6112,
      "grad_norm": 0.2528916001319885,
      "learning_rate": 3.2741390126134106e-05,
      "loss": 1.3596,
      "step": 191
    },
    {
      "epoch": 0.6144,
      "grad_norm": 0.24978062510490417,
      "learning_rate": 3.226975564787322e-05,
      "loss": 1.4193,
      "step": 192
    },
    {
      "epoch": 0.6176,
      "grad_norm": 0.24345175921916962,
      "learning_rate": 3.179991880500009e-05,
      "loss": 1.3805,
      "step": 193
    },
    {
      "epoch": 0.6208,
      "grad_norm": 0.23533454537391663,
      "learning_rate": 3.133192723336895e-05,
      "loss": 1.4492,
      "step": 194
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.2627878189086914,
      "learning_rate": 3.086582838174551e-05,
      "loss": 1.4946,
      "step": 195
    },
    {
      "epoch": 0.6272,
      "grad_norm": 0.2540966272354126,
      "learning_rate": 3.0401669506996256e-05,
      "loss": 1.3707,
      "step": 196
    },
    {
      "epoch": 0.6304,
      "grad_norm": 0.2797624170780182,
      "learning_rate": 2.9939497669297112e-05,
      "loss": 1.4569,
      "step": 197
    },
    {
      "epoch": 0.6336,
      "grad_norm": 0.26317062973976135,
      "learning_rate": 2.9479359727362173e-05,
      "loss": 1.4211,
      "step": 198
    },
    {
      "epoch": 0.6368,
      "grad_norm": 0.26931998133659363,
      "learning_rate": 2.9021302333692734e-05,
      "loss": 1.5163,
      "step": 199
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.25543731451034546,
      "learning_rate": 2.8565371929847284e-05,
      "loss": 1.4631,
      "step": 200
    },
    {
      "epoch": 0.64,
      "eval_loss": 1.3980482816696167,
      "eval_runtime": 7.5901,
      "eval_samples_per_second": 24.637,
      "eval_steps_per_second": 3.162,
      "step": 200
    },
    {
      "epoch": 0.6432,
      "grad_norm": 0.2544623911380768,
      "learning_rate": 2.811161474173297e-05,
      "loss": 1.4267,
      "step": 201
    },
    {
      "epoch": 0.6464,
      "grad_norm": 0.2442762404680252,
      "learning_rate": 2.7660076774918708e-05,
      "loss": 1.3796,
      "step": 202
    },
    {
      "epoch": 0.6496,
      "grad_norm": 0.25090402364730835,
      "learning_rate": 2.7210803809970853e-05,
      "loss": 1.4001,
      "step": 203
    },
    {
      "epoch": 0.6528,
      "grad_norm": 0.26768365502357483,
      "learning_rate": 2.6763841397811573e-05,
      "loss": 1.4171,
      "step": 204
    },
    {
      "epoch": 0.656,
      "grad_norm": 0.2525857090950012,
      "learning_rate": 2.631923485510054e-05,
      "loss": 1.4983,
      "step": 205
    },
    {
      "epoch": 0.6592,
      "grad_norm": 0.2851313650608063,
      "learning_rate": 2.587702925964034e-05,
      "loss": 1.4206,
      "step": 206
    },
    {
      "epoch": 0.6624,
      "grad_norm": 0.2895755469799042,
      "learning_rate": 2.5437269445806145e-05,
      "loss": 1.3938,
      "step": 207
    },
    {
      "epoch": 0.6656,
      "grad_norm": 0.2745216190814972,
      "learning_rate": 2.500000000000001e-05,
      "loss": 1.5219,
      "step": 208
    },
    {
      "epoch": 0.6688,
      "grad_norm": 0.27264168858528137,
      "learning_rate": 2.4565265256130394e-05,
      "loss": 1.3984,
      "step": 209
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.2782125771045685,
      "learning_rate": 2.4133109291117156e-05,
      "loss": 1.4158,
      "step": 210
    },
    {
      "epoch": 0.6752,
      "grad_norm": 0.27636054158210754,
      "learning_rate": 2.3703575920422795e-05,
      "loss": 1.4203,
      "step": 211
    },
    {
      "epoch": 0.6784,
      "grad_norm": 0.26429638266563416,
      "learning_rate": 2.3276708693609943e-05,
      "loss": 1.4712,
      "step": 212
    },
    {
      "epoch": 0.6816,
      "grad_norm": 0.2800976037979126,
      "learning_rate": 2.2852550889926067e-05,
      "loss": 1.4396,
      "step": 213
    },
    {
      "epoch": 0.6848,
      "grad_norm": 0.2516244947910309,
      "learning_rate": 2.243114551391542e-05,
      "loss": 1.3491,
      "step": 214
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.27617770433425903,
      "learning_rate": 2.20125352910589e-05,
      "loss": 1.4432,
      "step": 215
    },
    {
      "epoch": 0.6912,
      "grad_norm": 0.28031349182128906,
      "learning_rate": 2.1596762663442218e-05,
      "loss": 1.501,
      "step": 216
    },
    {
      "epoch": 0.6944,
      "grad_norm": 0.26621079444885254,
      "learning_rate": 2.118386978545274e-05,
      "loss": 1.4559,
      "step": 217
    },
    {
      "epoch": 0.6976,
      "grad_norm": 0.35484036803245544,
      "learning_rate": 2.077389851950557e-05,
      "loss": 1.4556,
      "step": 218
    },
    {
      "epoch": 0.7008,
      "grad_norm": 0.25343066453933716,
      "learning_rate": 2.0366890431799167e-05,
      "loss": 1.4131,
      "step": 219
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.26795828342437744,
      "learning_rate": 1.996288678810105e-05,
      "loss": 1.3934,
      "step": 220
    },
    {
      "epoch": 0.7072,
      "grad_norm": 0.2703782618045807,
      "learning_rate": 1.9561928549563968e-05,
      "loss": 1.4283,
      "step": 221
    },
    {
      "epoch": 0.7104,
      "grad_norm": 0.26581141352653503,
      "learning_rate": 1.9164056368572846e-05,
      "loss": 1.4456,
      "step": 222
    },
    {
      "epoch": 0.7136,
      "grad_norm": 0.26672855019569397,
      "learning_rate": 1.87693105846232e-05,
      "loss": 1.4373,
      "step": 223
    },
    {
      "epoch": 0.7168,
      "grad_norm": 0.2889585494995117,
      "learning_rate": 1.837773122023114e-05,
      "loss": 1.4826,
      "step": 224
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.24240721762180328,
      "learning_rate": 1.7989357976875603e-05,
      "loss": 1.4365,
      "step": 225
    },
    {
      "epoch": 0.7232,
      "grad_norm": 0.24733683466911316,
      "learning_rate": 1.760423023097307e-05,
      "loss": 1.3647,
      "step": 226
    },
    {
      "epoch": 0.7264,
      "grad_norm": 0.25231555104255676,
      "learning_rate": 1.7222387029885268e-05,
      "loss": 1.4714,
      "step": 227
    },
    {
      "epoch": 0.7296,
      "grad_norm": 0.3051114082336426,
      "learning_rate": 1.684386708796025e-05,
      "loss": 1.5442,
      "step": 228
    },
    {
      "epoch": 0.7328,
      "grad_norm": 0.2766067683696747,
      "learning_rate": 1.646870878260721e-05,
      "loss": 1.4065,
      "step": 229
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.2734323740005493,
      "learning_rate": 1.6096950150405454e-05,
      "loss": 1.541,
      "step": 230
    },
    {
      "epoch": 0.7392,
      "grad_norm": 0.2723216116428375,
      "learning_rate": 1.5728628883248007e-05,
      "loss": 1.4566,
      "step": 231
    },
    {
      "epoch": 0.7424,
      "grad_norm": 0.25756436586380005,
      "learning_rate": 1.536378232452003e-05,
      "loss": 1.4355,
      "step": 232
    },
    {
      "epoch": 0.7456,
      "grad_norm": 0.25798851251602173,
      "learning_rate": 1.5002447465312675e-05,
      "loss": 1.4093,
      "step": 233
    },
    {
      "epoch": 0.7488,
      "grad_norm": 0.2637953758239746,
      "learning_rate": 1.4644660940672627e-05,
      "loss": 1.4852,
      "step": 234
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.2635694146156311,
      "learning_rate": 1.429045902588777e-05,
      "loss": 1.4025,
      "step": 235
    },
    {
      "epoch": 0.7552,
      "grad_norm": 0.2832982838153839,
      "learning_rate": 1.3939877632809278e-05,
      "loss": 1.447,
      "step": 236
    },
    {
      "epoch": 0.7584,
      "grad_norm": 0.2817084789276123,
      "learning_rate": 1.3592952306210588e-05,
      "loss": 1.4552,
      "step": 237
    },
    {
      "epoch": 0.7616,
      "grad_norm": 0.2921307384967804,
      "learning_rate": 1.3249718220183583e-05,
      "loss": 1.5439,
      "step": 238
    },
    {
      "epoch": 0.7648,
      "grad_norm": 0.2791454493999481,
      "learning_rate": 1.2910210174572346e-05,
      "loss": 1.4349,
      "step": 239
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.26489782333374023,
      "learning_rate": 1.257446259144494e-05,
      "loss": 1.3963,
      "step": 240
    },
    {
      "epoch": 0.7712,
      "grad_norm": 0.26587939262390137,
      "learning_rate": 1.2242509511603317e-05,
      "loss": 1.4295,
      "step": 241
    },
    {
      "epoch": 0.7744,
      "grad_norm": 0.26221656799316406,
      "learning_rate": 1.1914384591132044e-05,
      "loss": 1.4692,
      "step": 242
    },
    {
      "epoch": 0.7776,
      "grad_norm": 0.25688961148262024,
      "learning_rate": 1.159012109798598e-05,
      "loss": 1.3477,
      "step": 243
    },
    {
      "epoch": 0.7808,
      "grad_norm": 0.257943719625473,
      "learning_rate": 1.1269751908617277e-05,
      "loss": 1.3849,
      "step": 244
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.27065420150756836,
      "learning_rate": 1.0953309504642128e-05,
      "loss": 1.4583,
      "step": 245
    },
    {
      "epoch": 0.7872,
      "grad_norm": 0.25459182262420654,
      "learning_rate": 1.0640825969547496e-05,
      "loss": 1.4627,
      "step": 246
    },
    {
      "epoch": 0.7904,
      "grad_norm": 0.26072585582733154,
      "learning_rate": 1.0332332985438248e-05,
      "loss": 1.4752,
      "step": 247
    },
    {
      "epoch": 0.7936,
      "grad_norm": 0.2623855173587799,
      "learning_rate": 1.0027861829824952e-05,
      "loss": 1.4595,
      "step": 248
    },
    {
      "epoch": 0.7968,
      "grad_norm": 0.25412553548812866,
      "learning_rate": 9.7274433724527e-06,
      "loss": 1.3843,
      "step": 249
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.26749154925346375,
      "learning_rate": 9.431108072171346e-06,
      "loss": 1.4127,
      "step": 250
    },
    {
      "epoch": 0.8032,
      "grad_norm": 0.25032082200050354,
      "learning_rate": 9.138885973847261e-06,
      "loss": 1.4443,
      "step": 251
    },
    {
      "epoch": 0.8064,
      "grad_norm": 0.2681770920753479,
      "learning_rate": 8.850806705317183e-06,
      "loss": 1.4574,
      "step": 252
    },
    {
      "epoch": 0.8096,
      "grad_norm": 0.27585551142692566,
      "learning_rate": 8.566899474384299e-06,
      "loss": 1.393,
      "step": 253
    },
    {
      "epoch": 0.8128,
      "grad_norm": 0.27517950534820557,
      "learning_rate": 8.287193065856935e-06,
      "loss": 1.4077,
      "step": 254
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.2767270505428314,
      "learning_rate": 8.011715838630107e-06,
      "loss": 1.4035,
      "step": 255
    },
    {
      "epoch": 0.8192,
      "grad_norm": 0.2777783274650574,
      "learning_rate": 7.740495722810271e-06,
      "loss": 1.3812,
      "step": 256
    },
    {
      "epoch": 0.8224,
      "grad_norm": 0.2871628403663635,
      "learning_rate": 7.4735602168835236e-06,
      "loss": 1.4838,
      "step": 257
    },
    {
      "epoch": 0.8256,
      "grad_norm": 0.2589623034000397,
      "learning_rate": 7.21093638492763e-06,
      "loss": 1.4387,
      "step": 258
    },
    {
      "epoch": 0.8288,
      "grad_norm": 0.2903566062450409,
      "learning_rate": 6.952650853867993e-06,
      "loss": 1.458,
      "step": 259
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.2690008878707886,
      "learning_rate": 6.698729810778065e-06,
      "loss": 1.4599,
      "step": 260
    },
    {
      "epoch": 0.8352,
      "grad_norm": 0.26548534631729126,
      "learning_rate": 6.449199000224221e-06,
      "loss": 1.3816,
      "step": 261
    },
    {
      "epoch": 0.8384,
      "grad_norm": 0.27272748947143555,
      "learning_rate": 6.204083721655607e-06,
      "loss": 1.4496,
      "step": 262
    },
    {
      "epoch": 0.8416,
      "grad_norm": 0.2588060796260834,
      "learning_rate": 5.9634088268390784e-06,
      "loss": 1.4013,
      "step": 263
    },
    {
      "epoch": 0.8448,
      "grad_norm": 0.26603302359580994,
      "learning_rate": 5.727198717339511e-06,
      "loss": 1.4052,
      "step": 264
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.2666459083557129,
      "learning_rate": 5.495477342045779e-06,
      "loss": 1.4312,
      "step": 265
    },
    {
      "epoch": 0.8512,
      "grad_norm": 0.28419485688209534,
      "learning_rate": 5.2682681947426375e-06,
      "loss": 1.5221,
      "step": 266
    },
    {
      "epoch": 0.8544,
      "grad_norm": 0.2756577134132385,
      "learning_rate": 5.045594311728707e-06,
      "loss": 1.4532,
      "step": 267
    },
    {
      "epoch": 0.8576,
      "grad_norm": 0.2694993317127228,
      "learning_rate": 4.827478269480895e-06,
      "loss": 1.4566,
      "step": 268
    },
    {
      "epoch": 0.8608,
      "grad_norm": 0.2688886225223541,
      "learning_rate": 4.613942182365372e-06,
      "loss": 1.4958,
      "step": 269
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.2681378722190857,
      "learning_rate": 4.405007700395497e-06,
      "loss": 1.4702,
      "step": 270
    },
    {
      "epoch": 0.8672,
      "grad_norm": 0.2613396644592285,
      "learning_rate": 4.200696007036703e-06,
      "loss": 1.439,
      "step": 271
    },
    {
      "epoch": 0.8704,
      "grad_norm": 0.2597465515136719,
      "learning_rate": 4.001027817058789e-06,
      "loss": 1.4583,
      "step": 272
    },
    {
      "epoch": 0.8736,
      "grad_norm": 0.2727283537387848,
      "learning_rate": 3.8060233744356633e-06,
      "loss": 1.4733,
      "step": 273
    },
    {
      "epoch": 0.8768,
      "grad_norm": 0.2723136246204376,
      "learning_rate": 3.615702450292857e-06,
      "loss": 1.5631,
      "step": 274
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.25954127311706543,
      "learning_rate": 3.4300843409029726e-06,
      "loss": 1.416,
      "step": 275
    },
    {
      "epoch": 0.8832,
      "grad_norm": 0.26100340485572815,
      "learning_rate": 3.249187865729264e-06,
      "loss": 1.4947,
      "step": 276
    },
    {
      "epoch": 0.8864,
      "grad_norm": 0.2803468406200409,
      "learning_rate": 3.0730313655175645e-06,
      "loss": 1.4211,
      "step": 277
    },
    {
      "epoch": 0.8896,
      "grad_norm": 0.2826118469238281,
      "learning_rate": 2.901632700436757e-06,
      "loss": 1.4008,
      "step": 278
    },
    {
      "epoch": 0.8928,
      "grad_norm": 0.2773844003677368,
      "learning_rate": 2.7350092482679836e-06,
      "loss": 1.4614,
      "step": 279
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.27408280968666077,
      "learning_rate": 2.573177902642726e-06,
      "loss": 1.4246,
      "step": 280
    },
    {
      "epoch": 0.8992,
      "grad_norm": 0.2626296281814575,
      "learning_rate": 2.416155071329973e-06,
      "loss": 1.4528,
      "step": 281
    },
    {
      "epoch": 0.9024,
      "grad_norm": 0.26879262924194336,
      "learning_rate": 2.2639566745727205e-06,
      "loss": 1.3971,
      "step": 282
    },
    {
      "epoch": 0.9056,
      "grad_norm": 0.27733302116394043,
      "learning_rate": 2.1165981434738026e-06,
      "loss": 1.4371,
      "step": 283
    },
    {
      "epoch": 0.9088,
      "grad_norm": 0.2591526508331299,
      "learning_rate": 1.974094418431388e-06,
      "loss": 1.4175,
      "step": 284
    },
    {
      "epoch": 0.912,
      "grad_norm": 0.2641414403915405,
      "learning_rate": 1.8364599476241862e-06,
      "loss": 1.4582,
      "step": 285
    },
    {
      "epoch": 0.9152,
      "grad_norm": 0.2432214468717575,
      "learning_rate": 1.70370868554659e-06,
      "loss": 1.393,
      "step": 286
    },
    {
      "epoch": 0.9184,
      "grad_norm": 0.26506781578063965,
      "learning_rate": 1.5758540915938368e-06,
      "loss": 1.4173,
      "step": 287
    },
    {
      "epoch": 0.9216,
      "grad_norm": 0.24388541281223297,
      "learning_rate": 1.4529091286973995e-06,
      "loss": 1.3935,
      "step": 288
    },
    {
      "epoch": 0.9248,
      "grad_norm": 0.2662675976753235,
      "learning_rate": 1.3348862620107038e-06,
      "loss": 1.5364,
      "step": 289
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.27720174193382263,
      "learning_rate": 1.2217974576453073e-06,
      "loss": 1.4731,
      "step": 290
    },
    {
      "epoch": 0.9312,
      "grad_norm": 0.27018508315086365,
      "learning_rate": 1.1136541814576573e-06,
      "loss": 1.4343,
      "step": 291
    },
    {
      "epoch": 0.9344,
      "grad_norm": 0.2885342240333557,
      "learning_rate": 1.0104673978866164e-06,
      "loss": 1.4658,
      "step": 292
    },
    {
      "epoch": 0.9376,
      "grad_norm": 0.282715767621994,
      "learning_rate": 9.122475688417953e-07,
      "loss": 1.4279,
      "step": 293
    },
    {
      "epoch": 0.9408,
      "grad_norm": 0.28337424993515015,
      "learning_rate": 8.190046526428242e-07,
      "loss": 1.4001,
      "step": 294
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.2626033127307892,
      "learning_rate": 7.307481030097152e-07,
      "loss": 1.4138,
      "step": 295
    },
    {
      "epoch": 0.9472,
      "grad_norm": 0.282471239566803,
      "learning_rate": 6.474868681043578e-07,
      "loss": 1.4231,
      "step": 296
    },
    {
      "epoch": 0.9504,
      "grad_norm": 0.27716928720474243,
      "learning_rate": 5.692293896232936e-07,
      "loss": 1.4524,
      "step": 297
    },
    {
      "epoch": 0.9536,
      "grad_norm": 0.26712900400161743,
      "learning_rate": 4.959836019417963e-07,
      "loss": 1.4512,
      "step": 298
    },
    {
      "epoch": 0.9568,
      "grad_norm": 0.2636631429195404,
      "learning_rate": 4.277569313094809e-07,
      "loss": 1.4135,
      "step": 299
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.27258235216140747,
      "learning_rate": 3.6455629509730136e-07,
      "loss": 1.4266,
      "step": 300
    },
    {
      "epoch": 0.9632,
      "grad_norm": 0.2821987569332123,
      "learning_rate": 3.0638810109626103e-07,
      "loss": 1.4534,
      "step": 301
    },
    {
      "epoch": 0.9664,
      "grad_norm": 0.2630206048488617,
      "learning_rate": 2.532582468677214e-07,
      "loss": 1.3938,
      "step": 302
    },
    {
      "epoch": 0.9696,
      "grad_norm": 0.28828489780426025,
      "learning_rate": 2.0517211914545254e-07,
      "loss": 1.5266,
      "step": 303
    },
    {
      "epoch": 0.9728,
      "grad_norm": 0.28436267375946045,
      "learning_rate": 1.6213459328950352e-07,
      "loss": 1.4299,
      "step": 304
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.2729770839214325,
      "learning_rate": 1.2415003279186987e-07,
      "loss": 1.4607,
      "step": 305
    },
    {
      "epoch": 0.9792,
      "grad_norm": 0.27856990694999695,
      "learning_rate": 9.12222888341252e-08,
      "loss": 1.4339,
      "step": 306
    },
    {
      "epoch": 0.9824,
      "grad_norm": 0.27079662680625916,
      "learning_rate": 6.335469989692256e-08,
      "loss": 1.3951,
      "step": 307
    },
    {
      "epoch": 0.9856,
      "grad_norm": 0.26752448081970215,
      "learning_rate": 4.055009142152067e-08,
      "loss": 1.4452,
      "step": 308
    },
    {
      "epoch": 0.9888,
      "grad_norm": 0.27847820520401,
      "learning_rate": 2.2810775523329773e-08,
      "loss": 1.4858,
      "step": 309
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.2668485939502716,
      "learning_rate": 1.0138550757493592e-08,
      "loss": 1.4191,
      "step": 310
    },
    {
      "epoch": 0.9952,
      "grad_norm": 0.25215187668800354,
      "learning_rate": 2.534701936512951e-09,
      "loss": 1.472,
      "step": 311
    },
    {
      "epoch": 0.9984,
      "grad_norm": 0.283875972032547,
      "learning_rate": 0.0,
      "loss": 1.4408,
      "step": 312
    }
  ],
  "logging_steps": 1,
  "max_steps": 312,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.764768815061074e+17,
  "train_batch_size": 12,
  "trial_name": null,
  "trial_params": null
}
