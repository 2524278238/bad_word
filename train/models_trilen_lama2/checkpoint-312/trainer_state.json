{
  "best_metric": 1.4672603607177734,
  "best_model_checkpoint": "/public/home/xiangyuduan/lyt/bad_word/train/models_trilen_lama2/checkpoint-200",
  "epoch": 0.9984,
  "eval_steps": 200,
  "global_step": 312,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0032,
      "grad_norm": 0.22593392431735992,
      "learning_rate": 9.999746529806349e-05,
      "loss": 1.925,
      "step": 1
    },
    {
      "epoch": 0.0064,
      "grad_norm": 0.25497129559516907,
      "learning_rate": 9.998986144924251e-05,
      "loss": 1.9433,
      "step": 2
    },
    {
      "epoch": 0.0096,
      "grad_norm": 0.30361831188201904,
      "learning_rate": 9.997718922447667e-05,
      "loss": 1.9245,
      "step": 3
    },
    {
      "epoch": 0.0128,
      "grad_norm": 0.41047248244285583,
      "learning_rate": 9.995944990857849e-05,
      "loss": 1.9035,
      "step": 4
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.47522902488708496,
      "learning_rate": 9.993664530010308e-05,
      "loss": 1.8737,
      "step": 5
    },
    {
      "epoch": 0.0192,
      "grad_norm": 0.49346479773521423,
      "learning_rate": 9.990877771116589e-05,
      "loss": 1.7374,
      "step": 6
    },
    {
      "epoch": 0.0224,
      "grad_norm": 0.5227760076522827,
      "learning_rate": 9.987584996720814e-05,
      "loss": 1.7678,
      "step": 7
    },
    {
      "epoch": 0.0256,
      "grad_norm": 0.5301647186279297,
      "learning_rate": 9.983786540671051e-05,
      "loss": 1.7387,
      "step": 8
    },
    {
      "epoch": 0.0288,
      "grad_norm": 0.5191665291786194,
      "learning_rate": 9.979482788085454e-05,
      "loss": 1.7512,
      "step": 9
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.42366042733192444,
      "learning_rate": 9.974674175313228e-05,
      "loss": 1.6683,
      "step": 10
    },
    {
      "epoch": 0.0352,
      "grad_norm": 0.49262920022010803,
      "learning_rate": 9.969361189890373e-05,
      "loss": 1.6595,
      "step": 11
    },
    {
      "epoch": 0.0384,
      "grad_norm": 0.5442118644714355,
      "learning_rate": 9.96354437049027e-05,
      "loss": 1.6261,
      "step": 12
    },
    {
      "epoch": 0.0416,
      "grad_norm": 0.5838924050331116,
      "learning_rate": 9.957224306869053e-05,
      "loss": 1.5701,
      "step": 13
    },
    {
      "epoch": 0.0448,
      "grad_norm": 0.5328853130340576,
      "learning_rate": 9.95040163980582e-05,
      "loss": 1.6024,
      "step": 14
    },
    {
      "epoch": 0.048,
      "grad_norm": 0.2894571125507355,
      "learning_rate": 9.943077061037671e-05,
      "loss": 1.6024,
      "step": 15
    },
    {
      "epoch": 0.0512,
      "grad_norm": 0.16700959205627441,
      "learning_rate": 9.935251313189564e-05,
      "loss": 1.6134,
      "step": 16
    },
    {
      "epoch": 0.0544,
      "grad_norm": 0.184756338596344,
      "learning_rate": 9.92692518969903e-05,
      "loss": 1.6206,
      "step": 17
    },
    {
      "epoch": 0.0576,
      "grad_norm": 0.1568620204925537,
      "learning_rate": 9.918099534735718e-05,
      "loss": 1.5461,
      "step": 18
    },
    {
      "epoch": 0.0608,
      "grad_norm": 0.17536252737045288,
      "learning_rate": 9.908775243115821e-05,
      "loss": 1.5173,
      "step": 19
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.16682304441928864,
      "learning_rate": 9.898953260211338e-05,
      "loss": 1.5688,
      "step": 20
    },
    {
      "epoch": 0.0672,
      "grad_norm": 0.14114919304847717,
      "learning_rate": 9.888634581854234e-05,
      "loss": 1.6018,
      "step": 21
    },
    {
      "epoch": 0.0704,
      "grad_norm": 0.15416131913661957,
      "learning_rate": 9.877820254235471e-05,
      "loss": 1.5899,
      "step": 22
    },
    {
      "epoch": 0.0736,
      "grad_norm": 0.13088618218898773,
      "learning_rate": 9.86651137379893e-05,
      "loss": 1.5183,
      "step": 23
    },
    {
      "epoch": 0.0768,
      "grad_norm": 0.14014120399951935,
      "learning_rate": 9.85470908713026e-05,
      "loss": 1.5831,
      "step": 24
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.14078623056411743,
      "learning_rate": 9.842414590840617e-05,
      "loss": 1.5381,
      "step": 25
    },
    {
      "epoch": 0.0832,
      "grad_norm": 0.14172953367233276,
      "learning_rate": 9.829629131445342e-05,
      "loss": 1.5897,
      "step": 26
    },
    {
      "epoch": 0.0864,
      "grad_norm": 0.156127467751503,
      "learning_rate": 9.816354005237583e-05,
      "loss": 1.5713,
      "step": 27
    },
    {
      "epoch": 0.0896,
      "grad_norm": 0.14436744153499603,
      "learning_rate": 9.802590558156862e-05,
      "loss": 1.5673,
      "step": 28
    },
    {
      "epoch": 0.0928,
      "grad_norm": 0.1376125067472458,
      "learning_rate": 9.78834018565262e-05,
      "loss": 1.5699,
      "step": 29
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.14200375974178314,
      "learning_rate": 9.773604332542729e-05,
      "loss": 1.6015,
      "step": 30
    },
    {
      "epoch": 0.0992,
      "grad_norm": 0.1446489542722702,
      "learning_rate": 9.758384492867003e-05,
      "loss": 1.5256,
      "step": 31
    },
    {
      "epoch": 0.1024,
      "grad_norm": 0.16929186880588531,
      "learning_rate": 9.742682209735727e-05,
      "loss": 1.5173,
      "step": 32
    },
    {
      "epoch": 0.1056,
      "grad_norm": 0.1526307463645935,
      "learning_rate": 9.726499075173201e-05,
      "loss": 1.4942,
      "step": 33
    },
    {
      "epoch": 0.1088,
      "grad_norm": 0.16427265107631683,
      "learning_rate": 9.709836729956325e-05,
      "loss": 1.53,
      "step": 34
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.1779160052537918,
      "learning_rate": 9.692696863448245e-05,
      "loss": 1.5346,
      "step": 35
    },
    {
      "epoch": 0.1152,
      "grad_norm": 0.15771278738975525,
      "learning_rate": 9.675081213427076e-05,
      "loss": 1.5719,
      "step": 36
    },
    {
      "epoch": 0.1184,
      "grad_norm": 0.1444624364376068,
      "learning_rate": 9.656991565909704e-05,
      "loss": 1.5387,
      "step": 37
    },
    {
      "epoch": 0.1216,
      "grad_norm": 0.1548173725605011,
      "learning_rate": 9.638429754970715e-05,
      "loss": 1.4301,
      "step": 38
    },
    {
      "epoch": 0.1248,
      "grad_norm": 0.1675691157579422,
      "learning_rate": 9.619397662556435e-05,
      "loss": 1.5176,
      "step": 39
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.1627681851387024,
      "learning_rate": 9.599897218294122e-05,
      "loss": 1.6145,
      "step": 40
    },
    {
      "epoch": 0.1312,
      "grad_norm": 0.1574498414993286,
      "learning_rate": 9.579930399296331e-05,
      "loss": 1.5546,
      "step": 41
    },
    {
      "epoch": 0.1344,
      "grad_norm": 0.15323293209075928,
      "learning_rate": 9.559499229960451e-05,
      "loss": 1.4991,
      "step": 42
    },
    {
      "epoch": 0.1376,
      "grad_norm": 0.1636238545179367,
      "learning_rate": 9.538605781763463e-05,
      "loss": 1.5236,
      "step": 43
    },
    {
      "epoch": 0.1408,
      "grad_norm": 0.15789468586444855,
      "learning_rate": 9.517252173051911e-05,
      "loss": 1.517,
      "step": 44
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.16366241872310638,
      "learning_rate": 9.495440568827129e-05,
      "loss": 1.5168,
      "step": 45
    },
    {
      "epoch": 0.1472,
      "grad_norm": 0.15927372872829437,
      "learning_rate": 9.473173180525737e-05,
      "loss": 1.5669,
      "step": 46
    },
    {
      "epoch": 0.1504,
      "grad_norm": 0.15983909368515015,
      "learning_rate": 9.450452265795423e-05,
      "loss": 1.558,
      "step": 47
    },
    {
      "epoch": 0.1536,
      "grad_norm": 0.16263271868228912,
      "learning_rate": 9.42728012826605e-05,
      "loss": 1.5271,
      "step": 48
    },
    {
      "epoch": 0.1568,
      "grad_norm": 0.15285846590995789,
      "learning_rate": 9.403659117316093e-05,
      "loss": 1.4535,
      "step": 49
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.16123074293136597,
      "learning_rate": 9.37959162783444e-05,
      "loss": 1.596,
      "step": 50
    },
    {
      "epoch": 0.1632,
      "grad_norm": 0.15505282580852509,
      "learning_rate": 9.355080099977578e-05,
      "loss": 1.4691,
      "step": 51
    },
    {
      "epoch": 0.1664,
      "grad_norm": 0.16886840760707855,
      "learning_rate": 9.330127018922194e-05,
      "loss": 1.5206,
      "step": 52
    },
    {
      "epoch": 0.1696,
      "grad_norm": 0.16610585153102875,
      "learning_rate": 9.3047349146132e-05,
      "loss": 1.541,
      "step": 53
    },
    {
      "epoch": 0.1728,
      "grad_norm": 0.17045453190803528,
      "learning_rate": 9.278906361507238e-05,
      "loss": 1.5359,
      "step": 54
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.17552550137043,
      "learning_rate": 9.252643978311649e-05,
      "loss": 1.5404,
      "step": 55
    },
    {
      "epoch": 0.1792,
      "grad_norm": 0.1752474159002304,
      "learning_rate": 9.225950427718975e-05,
      "loss": 1.5911,
      "step": 56
    },
    {
      "epoch": 0.1824,
      "grad_norm": 0.16311439871788025,
      "learning_rate": 9.19882841613699e-05,
      "loss": 1.5163,
      "step": 57
    },
    {
      "epoch": 0.1856,
      "grad_norm": 0.16053594648838043,
      "learning_rate": 9.171280693414307e-05,
      "loss": 1.5157,
      "step": 58
    },
    {
      "epoch": 0.1888,
      "grad_norm": 0.17182686924934387,
      "learning_rate": 9.143310052561571e-05,
      "loss": 1.4894,
      "step": 59
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.1710648238658905,
      "learning_rate": 9.114919329468282e-05,
      "loss": 1.5849,
      "step": 60
    },
    {
      "epoch": 0.1952,
      "grad_norm": 0.16170668601989746,
      "learning_rate": 9.086111402615273e-05,
      "loss": 1.519,
      "step": 61
    },
    {
      "epoch": 0.1984,
      "grad_norm": 0.16781075298786163,
      "learning_rate": 9.056889192782866e-05,
      "loss": 1.5215,
      "step": 62
    },
    {
      "epoch": 0.2016,
      "grad_norm": 0.16868571937084198,
      "learning_rate": 9.02725566275473e-05,
      "loss": 1.5381,
      "step": 63
    },
    {
      "epoch": 0.2048,
      "grad_norm": 0.16545835137367249,
      "learning_rate": 8.997213817017507e-05,
      "loss": 1.492,
      "step": 64
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.18686829507350922,
      "learning_rate": 8.966766701456177e-05,
      "loss": 1.4914,
      "step": 65
    },
    {
      "epoch": 0.2112,
      "grad_norm": 0.17821510136127472,
      "learning_rate": 8.935917403045251e-05,
      "loss": 1.5146,
      "step": 66
    },
    {
      "epoch": 0.2144,
      "grad_norm": 0.16694575548171997,
      "learning_rate": 8.904669049535789e-05,
      "loss": 1.515,
      "step": 67
    },
    {
      "epoch": 0.2176,
      "grad_norm": 0.17953936755657196,
      "learning_rate": 8.873024809138272e-05,
      "loss": 1.5175,
      "step": 68
    },
    {
      "epoch": 0.2208,
      "grad_norm": 0.17907072603702545,
      "learning_rate": 8.840987890201403e-05,
      "loss": 1.5743,
      "step": 69
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.18231512606143951,
      "learning_rate": 8.808561540886796e-05,
      "loss": 1.564,
      "step": 70
    },
    {
      "epoch": 0.2272,
      "grad_norm": 0.19188544154167175,
      "learning_rate": 8.775749048839669e-05,
      "loss": 1.5595,
      "step": 71
    },
    {
      "epoch": 0.2304,
      "grad_norm": 0.18380893766880035,
      "learning_rate": 8.742553740855506e-05,
      "loss": 1.5119,
      "step": 72
    },
    {
      "epoch": 0.2336,
      "grad_norm": 0.19725970923900604,
      "learning_rate": 8.708978982542765e-05,
      "loss": 1.5559,
      "step": 73
    },
    {
      "epoch": 0.2368,
      "grad_norm": 0.21221596002578735,
      "learning_rate": 8.675028177981643e-05,
      "loss": 1.5813,
      "step": 74
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.19300885498523712,
      "learning_rate": 8.640704769378942e-05,
      "loss": 1.5461,
      "step": 75
    },
    {
      "epoch": 0.2432,
      "grad_norm": 0.17915217578411102,
      "learning_rate": 8.606012236719073e-05,
      "loss": 1.5436,
      "step": 76
    },
    {
      "epoch": 0.2464,
      "grad_norm": 0.1918337047100067,
      "learning_rate": 8.570954097411223e-05,
      "loss": 1.5376,
      "step": 77
    },
    {
      "epoch": 0.2496,
      "grad_norm": 0.18808311223983765,
      "learning_rate": 8.535533905932738e-05,
      "loss": 1.5192,
      "step": 78
    },
    {
      "epoch": 0.2528,
      "grad_norm": 0.19626280665397644,
      "learning_rate": 8.499755253468733e-05,
      "loss": 1.4977,
      "step": 79
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.20246021449565887,
      "learning_rate": 8.463621767547998e-05,
      "loss": 1.4911,
      "step": 80
    },
    {
      "epoch": 0.2592,
      "grad_norm": 0.20772980153560638,
      "learning_rate": 8.427137111675199e-05,
      "loss": 1.5333,
      "step": 81
    },
    {
      "epoch": 0.2624,
      "grad_norm": 0.20208153128623962,
      "learning_rate": 8.390304984959454e-05,
      "loss": 1.5882,
      "step": 82
    },
    {
      "epoch": 0.2656,
      "grad_norm": 0.20280690491199493,
      "learning_rate": 8.353129121739281e-05,
      "loss": 1.5216,
      "step": 83
    },
    {
      "epoch": 0.2688,
      "grad_norm": 0.18291312456130981,
      "learning_rate": 8.315613291203976e-05,
      "loss": 1.4779,
      "step": 84
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.1797943413257599,
      "learning_rate": 8.277761297011475e-05,
      "loss": 1.5399,
      "step": 85
    },
    {
      "epoch": 0.2752,
      "grad_norm": 0.18718959391117096,
      "learning_rate": 8.239576976902695e-05,
      "loss": 1.5044,
      "step": 86
    },
    {
      "epoch": 0.2784,
      "grad_norm": 0.2050008326768875,
      "learning_rate": 8.201064202312441e-05,
      "loss": 1.4653,
      "step": 87
    },
    {
      "epoch": 0.2816,
      "grad_norm": 0.18374162912368774,
      "learning_rate": 8.162226877976887e-05,
      "loss": 1.472,
      "step": 88
    },
    {
      "epoch": 0.2848,
      "grad_norm": 0.18149255216121674,
      "learning_rate": 8.123068941537682e-05,
      "loss": 1.5277,
      "step": 89
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.1848534345626831,
      "learning_rate": 8.083594363142717e-05,
      "loss": 1.4511,
      "step": 90
    },
    {
      "epoch": 0.2912,
      "grad_norm": 0.19183681905269623,
      "learning_rate": 8.043807145043604e-05,
      "loss": 1.4717,
      "step": 91
    },
    {
      "epoch": 0.2944,
      "grad_norm": 0.19521771371364594,
      "learning_rate": 8.003711321189895e-05,
      "loss": 1.4826,
      "step": 92
    },
    {
      "epoch": 0.2976,
      "grad_norm": 0.18898427486419678,
      "learning_rate": 7.963310956820085e-05,
      "loss": 1.4878,
      "step": 93
    },
    {
      "epoch": 0.3008,
      "grad_norm": 0.18413718044757843,
      "learning_rate": 7.922610148049445e-05,
      "loss": 1.4926,
      "step": 94
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.18856607377529144,
      "learning_rate": 7.881613021454727e-05,
      "loss": 1.3823,
      "step": 95
    },
    {
      "epoch": 0.3072,
      "grad_norm": 0.1984027773141861,
      "learning_rate": 7.840323733655778e-05,
      "loss": 1.4737,
      "step": 96
    },
    {
      "epoch": 0.3104,
      "grad_norm": 0.21438926458358765,
      "learning_rate": 7.798746470894111e-05,
      "loss": 1.505,
      "step": 97
    },
    {
      "epoch": 0.3136,
      "grad_norm": 0.2030361443758011,
      "learning_rate": 7.756885448608459e-05,
      "loss": 1.5145,
      "step": 98
    },
    {
      "epoch": 0.3168,
      "grad_norm": 0.1957009881734848,
      "learning_rate": 7.714744911007394e-05,
      "loss": 1.4952,
      "step": 99
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.20878058671951294,
      "learning_rate": 7.672329130639005e-05,
      "loss": 1.5249,
      "step": 100
    },
    {
      "epoch": 0.3232,
      "grad_norm": 0.21048174798488617,
      "learning_rate": 7.62964240795772e-05,
      "loss": 1.4574,
      "step": 101
    },
    {
      "epoch": 0.3264,
      "grad_norm": 0.2128075808286667,
      "learning_rate": 7.586689070888284e-05,
      "loss": 1.5246,
      "step": 102
    },
    {
      "epoch": 0.3296,
      "grad_norm": 0.20880310237407684,
      "learning_rate": 7.543473474386961e-05,
      "loss": 1.4444,
      "step": 103
    },
    {
      "epoch": 0.3328,
      "grad_norm": 0.20017577707767487,
      "learning_rate": 7.500000000000001e-05,
      "loss": 1.5681,
      "step": 104
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.2040296047925949,
      "learning_rate": 7.456273055419388e-05,
      "loss": 1.4621,
      "step": 105
    },
    {
      "epoch": 0.3392,
      "grad_norm": 0.20936132967472076,
      "learning_rate": 7.412297074035967e-05,
      "loss": 1.4589,
      "step": 106
    },
    {
      "epoch": 0.3424,
      "grad_norm": 0.1953127086162567,
      "learning_rate": 7.368076514489947e-05,
      "loss": 1.4487,
      "step": 107
    },
    {
      "epoch": 0.3456,
      "grad_norm": 0.2107814997434616,
      "learning_rate": 7.323615860218843e-05,
      "loss": 1.4724,
      "step": 108
    },
    {
      "epoch": 0.3488,
      "grad_norm": 0.20714403688907623,
      "learning_rate": 7.278919619002916e-05,
      "loss": 1.5222,
      "step": 109
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.32482364773750305,
      "learning_rate": 7.233992322508129e-05,
      "loss": 1.525,
      "step": 110
    },
    {
      "epoch": 0.3552,
      "grad_norm": 0.2211877852678299,
      "learning_rate": 7.188838525826702e-05,
      "loss": 1.4508,
      "step": 111
    },
    {
      "epoch": 0.3584,
      "grad_norm": 0.2370341569185257,
      "learning_rate": 7.143462807015271e-05,
      "loss": 1.4739,
      "step": 112
    },
    {
      "epoch": 0.3616,
      "grad_norm": 0.2018561214208603,
      "learning_rate": 7.097869766630729e-05,
      "loss": 1.4811,
      "step": 113
    },
    {
      "epoch": 0.3648,
      "grad_norm": 0.22146813571453094,
      "learning_rate": 7.052064027263786e-05,
      "loss": 1.507,
      "step": 114
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.222476989030838,
      "learning_rate": 7.006050233070289e-05,
      "loss": 1.5267,
      "step": 115
    },
    {
      "epoch": 0.3712,
      "grad_norm": 0.2279663234949112,
      "learning_rate": 6.959833049300377e-05,
      "loss": 1.4952,
      "step": 116
    },
    {
      "epoch": 0.3744,
      "grad_norm": 0.22324524819850922,
      "learning_rate": 6.91341716182545e-05,
      "loss": 1.5437,
      "step": 117
    },
    {
      "epoch": 0.3776,
      "grad_norm": 0.21888333559036255,
      "learning_rate": 6.866807276663106e-05,
      "loss": 1.4928,
      "step": 118
    },
    {
      "epoch": 0.3808,
      "grad_norm": 0.2142038643360138,
      "learning_rate": 6.820008119499992e-05,
      "loss": 1.4577,
      "step": 119
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.22031088173389435,
      "learning_rate": 6.773024435212678e-05,
      "loss": 1.5005,
      "step": 120
    },
    {
      "epoch": 0.3872,
      "grad_norm": 0.2185700237751007,
      "learning_rate": 6.72586098738659e-05,
      "loss": 1.4833,
      "step": 121
    },
    {
      "epoch": 0.3904,
      "grad_norm": 0.22753453254699707,
      "learning_rate": 6.678522557833024e-05,
      "loss": 1.5347,
      "step": 122
    },
    {
      "epoch": 0.3936,
      "grad_norm": 0.21715666353702545,
      "learning_rate": 6.631013946104347e-05,
      "loss": 1.4838,
      "step": 123
    },
    {
      "epoch": 0.3968,
      "grad_norm": 0.21376143395900726,
      "learning_rate": 6.583339969007363e-05,
      "loss": 1.4499,
      "step": 124
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.2176460325717926,
      "learning_rate": 6.535505460114954e-05,
      "loss": 1.4408,
      "step": 125
    },
    {
      "epoch": 0.4032,
      "grad_norm": 0.2165469378232956,
      "learning_rate": 6.487515269276016e-05,
      "loss": 1.5277,
      "step": 126
    },
    {
      "epoch": 0.4064,
      "grad_norm": 0.21848233044147491,
      "learning_rate": 6.439374262123731e-05,
      "loss": 1.4319,
      "step": 127
    },
    {
      "epoch": 0.4096,
      "grad_norm": 0.202084481716156,
      "learning_rate": 6.391087319582264e-05,
      "loss": 1.5107,
      "step": 128
    },
    {
      "epoch": 0.4128,
      "grad_norm": 0.22891871631145477,
      "learning_rate": 6.342659337371885e-05,
      "loss": 1.4899,
      "step": 129
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.23061029613018036,
      "learning_rate": 6.294095225512603e-05,
      "loss": 1.5161,
      "step": 130
    },
    {
      "epoch": 0.4192,
      "grad_norm": 0.2233465313911438,
      "learning_rate": 6.24539990782636e-05,
      "loss": 1.5052,
      "step": 131
    },
    {
      "epoch": 0.4224,
      "grad_norm": 0.22587613761425018,
      "learning_rate": 6.19657832143779e-05,
      "loss": 1.4419,
      "step": 132
    },
    {
      "epoch": 0.4256,
      "grad_norm": 0.21092604100704193,
      "learning_rate": 6.147635416273678e-05,
      "loss": 1.4578,
      "step": 133
    },
    {
      "epoch": 0.4288,
      "grad_norm": 0.23101091384887695,
      "learning_rate": 6.098576154561087e-05,
      "loss": 1.4594,
      "step": 134
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.24888573586940765,
      "learning_rate": 6.049405510324238e-05,
      "loss": 1.4183,
      "step": 135
    },
    {
      "epoch": 0.4352,
      "grad_norm": 0.23933818936347961,
      "learning_rate": 6.0001284688802226e-05,
      "loss": 1.441,
      "step": 136
    },
    {
      "epoch": 0.4384,
      "grad_norm": 0.2479722648859024,
      "learning_rate": 5.950750026333534e-05,
      "loss": 1.5262,
      "step": 137
    },
    {
      "epoch": 0.4416,
      "grad_norm": 0.21473442018032074,
      "learning_rate": 5.90127518906953e-05,
      "loss": 1.4321,
      "step": 138
    },
    {
      "epoch": 0.4448,
      "grad_norm": 0.23519492149353027,
      "learning_rate": 5.851708973246841e-05,
      "loss": 1.4927,
      "step": 139
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.23891808092594147,
      "learning_rate": 5.8020564042888015e-05,
      "loss": 1.4324,
      "step": 140
    },
    {
      "epoch": 0.4512,
      "grad_norm": 0.22714057564735413,
      "learning_rate": 5.752322516373916e-05,
      "loss": 1.4145,
      "step": 141
    },
    {
      "epoch": 0.4544,
      "grad_norm": 0.23910793662071228,
      "learning_rate": 5.702512351925464e-05,
      "loss": 1.4507,
      "step": 142
    },
    {
      "epoch": 0.4576,
      "grad_norm": 0.23398970067501068,
      "learning_rate": 5.6526309611002594e-05,
      "loss": 1.5496,
      "step": 143
    },
    {
      "epoch": 0.4608,
      "grad_norm": 0.20416565239429474,
      "learning_rate": 5.602683401276615e-05,
      "loss": 1.4079,
      "step": 144
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.2394026815891266,
      "learning_rate": 5.5526747365416e-05,
      "loss": 1.4926,
      "step": 145
    },
    {
      "epoch": 0.4672,
      "grad_norm": 0.21432876586914062,
      "learning_rate": 5.502610037177586e-05,
      "loss": 1.429,
      "step": 146
    },
    {
      "epoch": 0.4704,
      "grad_norm": 0.2459411770105362,
      "learning_rate": 5.45249437914819e-05,
      "loss": 1.5117,
      "step": 147
    },
    {
      "epoch": 0.4736,
      "grad_norm": 0.22080062329769135,
      "learning_rate": 5.402332843583631e-05,
      "loss": 1.4916,
      "step": 148
    },
    {
      "epoch": 0.4768,
      "grad_norm": 0.22883746027946472,
      "learning_rate": 5.35213051626556e-05,
      "loss": 1.4111,
      "step": 149
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.22886891663074493,
      "learning_rate": 5.3018924871114305e-05,
      "loss": 1.5179,
      "step": 150
    },
    {
      "epoch": 0.4832,
      "grad_norm": 0.24306248128414154,
      "learning_rate": 5.2516238496584335e-05,
      "loss": 1.5725,
      "step": 151
    },
    {
      "epoch": 0.4864,
      "grad_norm": 0.22616137564182281,
      "learning_rate": 5.201329700547076e-05,
      "loss": 1.4687,
      "step": 152
    },
    {
      "epoch": 0.4896,
      "grad_norm": 0.23094163835048676,
      "learning_rate": 5.151015139004445e-05,
      "loss": 1.4509,
      "step": 153
    },
    {
      "epoch": 0.4928,
      "grad_norm": 0.22598963975906372,
      "learning_rate": 5.100685266327202e-05,
      "loss": 1.4055,
      "step": 154
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.24122671782970428,
      "learning_rate": 5.0503451853643776e-05,
      "loss": 1.5178,
      "step": 155
    },
    {
      "epoch": 0.4992,
      "grad_norm": 0.24888333678245544,
      "learning_rate": 5e-05,
      "loss": 1.5082,
      "step": 156
    },
    {
      "epoch": 0.5024,
      "grad_norm": 0.24052703380584717,
      "learning_rate": 4.949654814635623e-05,
      "loss": 1.5261,
      "step": 157
    },
    {
      "epoch": 0.5056,
      "grad_norm": 0.239439457654953,
      "learning_rate": 4.899314733672799e-05,
      "loss": 1.4321,
      "step": 158
    },
    {
      "epoch": 0.5088,
      "grad_norm": 0.22821840643882751,
      "learning_rate": 4.848984860995557e-05,
      "loss": 1.3868,
      "step": 159
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.22580009698867798,
      "learning_rate": 4.798670299452926e-05,
      "loss": 1.4541,
      "step": 160
    },
    {
      "epoch": 0.5152,
      "grad_norm": 0.25823017954826355,
      "learning_rate": 4.748376150341566e-05,
      "loss": 1.5128,
      "step": 161
    },
    {
      "epoch": 0.5184,
      "grad_norm": 0.2459440678358078,
      "learning_rate": 4.6981075128885693e-05,
      "loss": 1.4833,
      "step": 162
    },
    {
      "epoch": 0.5216,
      "grad_norm": 0.2299950122833252,
      "learning_rate": 4.6478694837344404e-05,
      "loss": 1.4959,
      "step": 163
    },
    {
      "epoch": 0.5248,
      "grad_norm": 0.2217624932527542,
      "learning_rate": 4.597667156416371e-05,
      "loss": 1.4817,
      "step": 164
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.24887384474277496,
      "learning_rate": 4.547505620851811e-05,
      "loss": 1.4753,
      "step": 165
    },
    {
      "epoch": 0.5312,
      "grad_norm": 0.2386995255947113,
      "learning_rate": 4.4973899628224154e-05,
      "loss": 1.4689,
      "step": 166
    },
    {
      "epoch": 0.5344,
      "grad_norm": 0.23668792843818665,
      "learning_rate": 4.4473252634584015e-05,
      "loss": 1.4825,
      "step": 167
    },
    {
      "epoch": 0.5376,
      "grad_norm": 0.2386280745267868,
      "learning_rate": 4.397316598723385e-05,
      "loss": 1.4614,
      "step": 168
    },
    {
      "epoch": 0.5408,
      "grad_norm": 0.22242607176303864,
      "learning_rate": 4.347369038899744e-05,
      "loss": 1.4587,
      "step": 169
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.2444268763065338,
      "learning_rate": 4.297487648074538e-05,
      "loss": 1.5169,
      "step": 170
    },
    {
      "epoch": 0.5472,
      "grad_norm": 0.25807464122772217,
      "learning_rate": 4.2476774836260845e-05,
      "loss": 1.39,
      "step": 171
    },
    {
      "epoch": 0.5504,
      "grad_norm": 0.23993034660816193,
      "learning_rate": 4.197943595711198e-05,
      "loss": 1.4558,
      "step": 172
    },
    {
      "epoch": 0.5536,
      "grad_norm": 0.2313421368598938,
      "learning_rate": 4.1482910267531585e-05,
      "loss": 1.5258,
      "step": 173
    },
    {
      "epoch": 0.5568,
      "grad_norm": 0.24976353347301483,
      "learning_rate": 4.0987248109304714e-05,
      "loss": 1.4089,
      "step": 174
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.2396242916584015,
      "learning_rate": 4.049249973666467e-05,
      "loss": 1.4876,
      "step": 175
    },
    {
      "epoch": 0.5632,
      "grad_norm": 0.24623340368270874,
      "learning_rate": 3.9998715311197785e-05,
      "loss": 1.4859,
      "step": 176
    },
    {
      "epoch": 0.5664,
      "grad_norm": 0.256483793258667,
      "learning_rate": 3.950594489675763e-05,
      "loss": 1.4566,
      "step": 177
    },
    {
      "epoch": 0.5696,
      "grad_norm": 0.24051989614963531,
      "learning_rate": 3.901423845438916e-05,
      "loss": 1.5357,
      "step": 178
    },
    {
      "epoch": 0.5728,
      "grad_norm": 0.2609058916568756,
      "learning_rate": 3.852364583726324e-05,
      "loss": 1.4261,
      "step": 179
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.23997069895267487,
      "learning_rate": 3.803421678562213e-05,
      "loss": 1.4952,
      "step": 180
    },
    {
      "epoch": 0.5792,
      "grad_norm": 0.23558861017227173,
      "learning_rate": 3.754600092173641e-05,
      "loss": 1.4587,
      "step": 181
    },
    {
      "epoch": 0.5824,
      "grad_norm": 0.23973232507705688,
      "learning_rate": 3.705904774487396e-05,
      "loss": 1.5583,
      "step": 182
    },
    {
      "epoch": 0.5856,
      "grad_norm": 0.24785520136356354,
      "learning_rate": 3.657340662628116e-05,
      "loss": 1.4178,
      "step": 183
    },
    {
      "epoch": 0.5888,
      "grad_norm": 0.25010424852371216,
      "learning_rate": 3.608912680417737e-05,
      "loss": 1.4348,
      "step": 184
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.2511488199234009,
      "learning_rate": 3.5606257378762696e-05,
      "loss": 1.5101,
      "step": 185
    },
    {
      "epoch": 0.5952,
      "grad_norm": 0.2455495297908783,
      "learning_rate": 3.512484730723986e-05,
      "loss": 1.4403,
      "step": 186
    },
    {
      "epoch": 0.5984,
      "grad_norm": 0.24979116022586823,
      "learning_rate": 3.464494539885047e-05,
      "loss": 1.4052,
      "step": 187
    },
    {
      "epoch": 0.6016,
      "grad_norm": 0.2368009239435196,
      "learning_rate": 3.4166600309926387e-05,
      "loss": 1.4913,
      "step": 188
    },
    {
      "epoch": 0.6048,
      "grad_norm": 0.25149914622306824,
      "learning_rate": 3.368986053895655e-05,
      "loss": 1.4712,
      "step": 189
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.2440742552280426,
      "learning_rate": 3.3214774421669774e-05,
      "loss": 1.3749,
      "step": 190
    },
    {
      "epoch": 0.6112,
      "grad_norm": 0.2386358380317688,
      "learning_rate": 3.2741390126134106e-05,
      "loss": 1.4104,
      "step": 191
    },
    {
      "epoch": 0.6144,
      "grad_norm": 0.25337132811546326,
      "learning_rate": 3.226975564787322e-05,
      "loss": 1.4674,
      "step": 192
    },
    {
      "epoch": 0.6176,
      "grad_norm": 0.2432161271572113,
      "learning_rate": 3.179991880500009e-05,
      "loss": 1.3851,
      "step": 193
    },
    {
      "epoch": 0.6208,
      "grad_norm": 0.2497641146183014,
      "learning_rate": 3.133192723336895e-05,
      "loss": 1.478,
      "step": 194
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.25351008772850037,
      "learning_rate": 3.086582838174551e-05,
      "loss": 1.4887,
      "step": 195
    },
    {
      "epoch": 0.6272,
      "grad_norm": 0.2386268526315689,
      "learning_rate": 3.0401669506996256e-05,
      "loss": 1.5024,
      "step": 196
    },
    {
      "epoch": 0.6304,
      "grad_norm": 0.26167598366737366,
      "learning_rate": 2.9939497669297112e-05,
      "loss": 1.5306,
      "step": 197
    },
    {
      "epoch": 0.6336,
      "grad_norm": 0.2525985836982727,
      "learning_rate": 2.9479359727362173e-05,
      "loss": 1.4828,
      "step": 198
    },
    {
      "epoch": 0.6368,
      "grad_norm": 0.24866130948066711,
      "learning_rate": 2.9021302333692734e-05,
      "loss": 1.5163,
      "step": 199
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.26124536991119385,
      "learning_rate": 2.8565371929847284e-05,
      "loss": 1.5212,
      "step": 200
    },
    {
      "epoch": 0.64,
      "eval_loss": 1.4672603607177734,
      "eval_runtime": 8.0433,
      "eval_samples_per_second": 23.249,
      "eval_steps_per_second": 2.984,
      "step": 200
    },
    {
      "epoch": 0.6432,
      "grad_norm": 0.2447228878736496,
      "learning_rate": 2.811161474173297e-05,
      "loss": 1.4131,
      "step": 201
    },
    {
      "epoch": 0.6464,
      "grad_norm": 0.2596898078918457,
      "learning_rate": 2.7660076774918708e-05,
      "loss": 1.3246,
      "step": 202
    },
    {
      "epoch": 0.6496,
      "grad_norm": 0.24074144661426544,
      "learning_rate": 2.7210803809970853e-05,
      "loss": 1.4396,
      "step": 203
    },
    {
      "epoch": 0.6528,
      "grad_norm": 0.2594120502471924,
      "learning_rate": 2.6763841397811573e-05,
      "loss": 1.4508,
      "step": 204
    },
    {
      "epoch": 0.656,
      "grad_norm": 0.24571636319160461,
      "learning_rate": 2.631923485510054e-05,
      "loss": 1.5001,
      "step": 205
    },
    {
      "epoch": 0.6592,
      "grad_norm": 0.26884177327156067,
      "learning_rate": 2.587702925964034e-05,
      "loss": 1.4321,
      "step": 206
    },
    {
      "epoch": 0.6624,
      "grad_norm": 0.26435527205467224,
      "learning_rate": 2.5437269445806145e-05,
      "loss": 1.4204,
      "step": 207
    },
    {
      "epoch": 0.6656,
      "grad_norm": 0.2698594033718109,
      "learning_rate": 2.500000000000001e-05,
      "loss": 1.5275,
      "step": 208
    },
    {
      "epoch": 0.6688,
      "grad_norm": 0.24502263963222504,
      "learning_rate": 2.4565265256130394e-05,
      "loss": 1.4263,
      "step": 209
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.2706025540828705,
      "learning_rate": 2.4133109291117156e-05,
      "loss": 1.4125,
      "step": 210
    },
    {
      "epoch": 0.6752,
      "grad_norm": 0.27092069387435913,
      "learning_rate": 2.3703575920422795e-05,
      "loss": 1.4715,
      "step": 211
    },
    {
      "epoch": 0.6784,
      "grad_norm": 0.26799848675727844,
      "learning_rate": 2.3276708693609943e-05,
      "loss": 1.4928,
      "step": 212
    },
    {
      "epoch": 0.6816,
      "grad_norm": 0.27581465244293213,
      "learning_rate": 2.2852550889926067e-05,
      "loss": 1.513,
      "step": 213
    },
    {
      "epoch": 0.6848,
      "grad_norm": 0.24674610793590546,
      "learning_rate": 2.243114551391542e-05,
      "loss": 1.3653,
      "step": 214
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.24468892812728882,
      "learning_rate": 2.20125352910589e-05,
      "loss": 1.4637,
      "step": 215
    },
    {
      "epoch": 0.6912,
      "grad_norm": 0.2616720497608185,
      "learning_rate": 2.1596762663442218e-05,
      "loss": 1.5286,
      "step": 216
    },
    {
      "epoch": 0.6944,
      "grad_norm": 0.2576070725917816,
      "learning_rate": 2.118386978545274e-05,
      "loss": 1.5009,
      "step": 217
    },
    {
      "epoch": 0.6976,
      "grad_norm": 0.3000074625015259,
      "learning_rate": 2.077389851950557e-05,
      "loss": 1.505,
      "step": 218
    },
    {
      "epoch": 0.7008,
      "grad_norm": 0.24880291521549225,
      "learning_rate": 2.0366890431799167e-05,
      "loss": 1.4065,
      "step": 219
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.25942954421043396,
      "learning_rate": 1.996288678810105e-05,
      "loss": 1.4407,
      "step": 220
    },
    {
      "epoch": 0.7072,
      "grad_norm": 0.2639886140823364,
      "learning_rate": 1.9561928549563968e-05,
      "loss": 1.4792,
      "step": 221
    },
    {
      "epoch": 0.7104,
      "grad_norm": 0.2735503613948822,
      "learning_rate": 1.9164056368572846e-05,
      "loss": 1.4821,
      "step": 222
    },
    {
      "epoch": 0.7136,
      "grad_norm": 0.2586965262889862,
      "learning_rate": 1.87693105846232e-05,
      "loss": 1.4446,
      "step": 223
    },
    {
      "epoch": 0.7168,
      "grad_norm": 0.27955111861228943,
      "learning_rate": 1.837773122023114e-05,
      "loss": 1.4814,
      "step": 224
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.24879519641399384,
      "learning_rate": 1.7989357976875603e-05,
      "loss": 1.4633,
      "step": 225
    },
    {
      "epoch": 0.7232,
      "grad_norm": 0.2606339156627655,
      "learning_rate": 1.760423023097307e-05,
      "loss": 1.4324,
      "step": 226
    },
    {
      "epoch": 0.7264,
      "grad_norm": 0.24389885365962982,
      "learning_rate": 1.7222387029885268e-05,
      "loss": 1.4979,
      "step": 227
    },
    {
      "epoch": 0.7296,
      "grad_norm": 0.2624785602092743,
      "learning_rate": 1.684386708796025e-05,
      "loss": 1.4854,
      "step": 228
    },
    {
      "epoch": 0.7328,
      "grad_norm": 0.259911447763443,
      "learning_rate": 1.646870878260721e-05,
      "loss": 1.4459,
      "step": 229
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.2674572467803955,
      "learning_rate": 1.6096950150405454e-05,
      "loss": 1.5722,
      "step": 230
    },
    {
      "epoch": 0.7392,
      "grad_norm": 0.28844311833381653,
      "learning_rate": 1.5728628883248007e-05,
      "loss": 1.5288,
      "step": 231
    },
    {
      "epoch": 0.7424,
      "grad_norm": 0.26286354660987854,
      "learning_rate": 1.536378232452003e-05,
      "loss": 1.4629,
      "step": 232
    },
    {
      "epoch": 0.7456,
      "grad_norm": 0.24752359092235565,
      "learning_rate": 1.5002447465312675e-05,
      "loss": 1.46,
      "step": 233
    },
    {
      "epoch": 0.7488,
      "grad_norm": 0.25535571575164795,
      "learning_rate": 1.4644660940672627e-05,
      "loss": 1.4269,
      "step": 234
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.254596084356308,
      "learning_rate": 1.429045902588777e-05,
      "loss": 1.4806,
      "step": 235
    },
    {
      "epoch": 0.7552,
      "grad_norm": 0.2747029662132263,
      "learning_rate": 1.3939877632809278e-05,
      "loss": 1.4355,
      "step": 236
    },
    {
      "epoch": 0.7584,
      "grad_norm": 0.26811882853507996,
      "learning_rate": 1.3592952306210588e-05,
      "loss": 1.4961,
      "step": 237
    },
    {
      "epoch": 0.7616,
      "grad_norm": 0.2625771462917328,
      "learning_rate": 1.3249718220183583e-05,
      "loss": 1.5011,
      "step": 238
    },
    {
      "epoch": 0.7648,
      "grad_norm": 0.2698844075202942,
      "learning_rate": 1.2910210174572346e-05,
      "loss": 1.4429,
      "step": 239
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.2525366246700287,
      "learning_rate": 1.257446259144494e-05,
      "loss": 1.3933,
      "step": 240
    },
    {
      "epoch": 0.7712,
      "grad_norm": 0.2762858271598816,
      "learning_rate": 1.2242509511603317e-05,
      "loss": 1.4554,
      "step": 241
    },
    {
      "epoch": 0.7744,
      "grad_norm": 0.2613878548145294,
      "learning_rate": 1.1914384591132044e-05,
      "loss": 1.4986,
      "step": 242
    },
    {
      "epoch": 0.7776,
      "grad_norm": 0.2794515788555145,
      "learning_rate": 1.159012109798598e-05,
      "loss": 1.3705,
      "step": 243
    },
    {
      "epoch": 0.7808,
      "grad_norm": 0.2779041826725006,
      "learning_rate": 1.1269751908617277e-05,
      "loss": 1.4117,
      "step": 244
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.27337849140167236,
      "learning_rate": 1.0953309504642128e-05,
      "loss": 1.5131,
      "step": 245
    },
    {
      "epoch": 0.7872,
      "grad_norm": 0.2497044950723648,
      "learning_rate": 1.0640825969547496e-05,
      "loss": 1.4046,
      "step": 246
    },
    {
      "epoch": 0.7904,
      "grad_norm": 0.2607734203338623,
      "learning_rate": 1.0332332985438248e-05,
      "loss": 1.511,
      "step": 247
    },
    {
      "epoch": 0.7936,
      "grad_norm": 0.2587911784648895,
      "learning_rate": 1.0027861829824952e-05,
      "loss": 1.484,
      "step": 248
    },
    {
      "epoch": 0.7968,
      "grad_norm": 0.25166985392570496,
      "learning_rate": 9.7274433724527e-06,
      "loss": 1.4197,
      "step": 249
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.2565866708755493,
      "learning_rate": 9.431108072171346e-06,
      "loss": 1.4643,
      "step": 250
    },
    {
      "epoch": 0.8032,
      "grad_norm": 0.25877827405929565,
      "learning_rate": 9.138885973847261e-06,
      "loss": 1.4615,
      "step": 251
    },
    {
      "epoch": 0.8064,
      "grad_norm": 0.26713424921035767,
      "learning_rate": 8.850806705317183e-06,
      "loss": 1.4454,
      "step": 252
    },
    {
      "epoch": 0.8096,
      "grad_norm": 0.26400840282440186,
      "learning_rate": 8.566899474384299e-06,
      "loss": 1.4533,
      "step": 253
    },
    {
      "epoch": 0.8128,
      "grad_norm": 0.26423180103302,
      "learning_rate": 8.287193065856935e-06,
      "loss": 1.4627,
      "step": 254
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.2666389048099518,
      "learning_rate": 8.011715838630107e-06,
      "loss": 1.4693,
      "step": 255
    },
    {
      "epoch": 0.8192,
      "grad_norm": 0.25642895698547363,
      "learning_rate": 7.740495722810271e-06,
      "loss": 1.4456,
      "step": 256
    },
    {
      "epoch": 0.8224,
      "grad_norm": 0.27115872502326965,
      "learning_rate": 7.4735602168835236e-06,
      "loss": 1.5126,
      "step": 257
    },
    {
      "epoch": 0.8256,
      "grad_norm": 0.2556648254394531,
      "learning_rate": 7.21093638492763e-06,
      "loss": 1.4209,
      "step": 258
    },
    {
      "epoch": 0.8288,
      "grad_norm": 0.2725200057029724,
      "learning_rate": 6.952650853867993e-06,
      "loss": 1.4459,
      "step": 259
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.2615889012813568,
      "learning_rate": 6.698729810778065e-06,
      "loss": 1.5055,
      "step": 260
    },
    {
      "epoch": 0.8352,
      "grad_norm": 0.25070518255233765,
      "learning_rate": 6.449199000224221e-06,
      "loss": 1.4107,
      "step": 261
    },
    {
      "epoch": 0.8384,
      "grad_norm": 0.2557562589645386,
      "learning_rate": 6.204083721655607e-06,
      "loss": 1.4833,
      "step": 262
    },
    {
      "epoch": 0.8416,
      "grad_norm": 0.26135674118995667,
      "learning_rate": 5.9634088268390784e-06,
      "loss": 1.4677,
      "step": 263
    },
    {
      "epoch": 0.8448,
      "grad_norm": 0.25978344678878784,
      "learning_rate": 5.727198717339511e-06,
      "loss": 1.4825,
      "step": 264
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.2834310233592987,
      "learning_rate": 5.495477342045779e-06,
      "loss": 1.4248,
      "step": 265
    },
    {
      "epoch": 0.8512,
      "grad_norm": 0.2777802646160126,
      "learning_rate": 5.2682681947426375e-06,
      "loss": 1.5454,
      "step": 266
    },
    {
      "epoch": 0.8544,
      "grad_norm": 0.2684234380722046,
      "learning_rate": 5.045594311728707e-06,
      "loss": 1.4752,
      "step": 267
    },
    {
      "epoch": 0.8576,
      "grad_norm": 0.2915599048137665,
      "learning_rate": 4.827478269480895e-06,
      "loss": 1.507,
      "step": 268
    },
    {
      "epoch": 0.8608,
      "grad_norm": 0.26339516043663025,
      "learning_rate": 4.613942182365372e-06,
      "loss": 1.4842,
      "step": 269
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.2695642113685608,
      "learning_rate": 4.405007700395497e-06,
      "loss": 1.4929,
      "step": 270
    },
    {
      "epoch": 0.8672,
      "grad_norm": 0.2674460709095001,
      "learning_rate": 4.200696007036703e-06,
      "loss": 1.4593,
      "step": 271
    },
    {
      "epoch": 0.8704,
      "grad_norm": 0.26035234332084656,
      "learning_rate": 4.001027817058789e-06,
      "loss": 1.4859,
      "step": 272
    },
    {
      "epoch": 0.8736,
      "grad_norm": 0.2583318054676056,
      "learning_rate": 3.8060233744356633e-06,
      "loss": 1.5185,
      "step": 273
    },
    {
      "epoch": 0.8768,
      "grad_norm": 0.2732692360877991,
      "learning_rate": 3.615702450292857e-06,
      "loss": 1.5636,
      "step": 274
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.25344616174697876,
      "learning_rate": 3.4300843409029726e-06,
      "loss": 1.4309,
      "step": 275
    },
    {
      "epoch": 0.8832,
      "grad_norm": 0.25392186641693115,
      "learning_rate": 3.249187865729264e-06,
      "loss": 1.4672,
      "step": 276
    },
    {
      "epoch": 0.8864,
      "grad_norm": 0.2673167884349823,
      "learning_rate": 3.0730313655175645e-06,
      "loss": 1.4942,
      "step": 277
    },
    {
      "epoch": 0.8896,
      "grad_norm": 0.27586090564727783,
      "learning_rate": 2.901632700436757e-06,
      "loss": 1.4655,
      "step": 278
    },
    {
      "epoch": 0.8928,
      "grad_norm": 0.25704240798950195,
      "learning_rate": 2.7350092482679836e-06,
      "loss": 1.4339,
      "step": 279
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.2655128836631775,
      "learning_rate": 2.573177902642726e-06,
      "loss": 1.4395,
      "step": 280
    },
    {
      "epoch": 0.8992,
      "grad_norm": 0.2533382475376129,
      "learning_rate": 2.416155071329973e-06,
      "loss": 1.4757,
      "step": 281
    },
    {
      "epoch": 0.9024,
      "grad_norm": 0.2530548572540283,
      "learning_rate": 2.2639566745727205e-06,
      "loss": 1.4443,
      "step": 282
    },
    {
      "epoch": 0.9056,
      "grad_norm": 0.2580171525478363,
      "learning_rate": 2.1165981434738026e-06,
      "loss": 1.4803,
      "step": 283
    },
    {
      "epoch": 0.9088,
      "grad_norm": 0.26343581080436707,
      "learning_rate": 1.974094418431388e-06,
      "loss": 1.4266,
      "step": 284
    },
    {
      "epoch": 0.912,
      "grad_norm": 0.263458788394928,
      "learning_rate": 1.8364599476241862e-06,
      "loss": 1.4621,
      "step": 285
    },
    {
      "epoch": 0.9152,
      "grad_norm": 0.25288498401641846,
      "learning_rate": 1.70370868554659e-06,
      "loss": 1.4226,
      "step": 286
    },
    {
      "epoch": 0.9184,
      "grad_norm": 0.2488340586423874,
      "learning_rate": 1.5758540915938368e-06,
      "loss": 1.4856,
      "step": 287
    },
    {
      "epoch": 0.9216,
      "grad_norm": 0.24648267030715942,
      "learning_rate": 1.4529091286973995e-06,
      "loss": 1.3862,
      "step": 288
    },
    {
      "epoch": 0.9248,
      "grad_norm": 0.2647477090358734,
      "learning_rate": 1.3348862620107038e-06,
      "loss": 1.4965,
      "step": 289
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.2643188238143921,
      "learning_rate": 1.2217974576453073e-06,
      "loss": 1.5109,
      "step": 290
    },
    {
      "epoch": 0.9312,
      "grad_norm": 0.26343074440956116,
      "learning_rate": 1.1136541814576573e-06,
      "loss": 1.4609,
      "step": 291
    },
    {
      "epoch": 0.9344,
      "grad_norm": 0.28005775809288025,
      "learning_rate": 1.0104673978866164e-06,
      "loss": 1.4622,
      "step": 292
    },
    {
      "epoch": 0.9376,
      "grad_norm": 0.2742461860179901,
      "learning_rate": 9.122475688417953e-07,
      "loss": 1.428,
      "step": 293
    },
    {
      "epoch": 0.9408,
      "grad_norm": 0.2658211886882782,
      "learning_rate": 8.190046526428242e-07,
      "loss": 1.4437,
      "step": 294
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.25619053840637207,
      "learning_rate": 7.307481030097152e-07,
      "loss": 1.4218,
      "step": 295
    },
    {
      "epoch": 0.9472,
      "grad_norm": 0.272723913192749,
      "learning_rate": 6.474868681043578e-07,
      "loss": 1.4622,
      "step": 296
    },
    {
      "epoch": 0.9504,
      "grad_norm": 0.25923001766204834,
      "learning_rate": 5.692293896232936e-07,
      "loss": 1.4304,
      "step": 297
    },
    {
      "epoch": 0.9536,
      "grad_norm": 0.28395164012908936,
      "learning_rate": 4.959836019417963e-07,
      "loss": 1.4515,
      "step": 298
    },
    {
      "epoch": 0.9568,
      "grad_norm": 0.27686312794685364,
      "learning_rate": 4.277569313094809e-07,
      "loss": 1.4732,
      "step": 299
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.28281769156455994,
      "learning_rate": 3.6455629509730136e-07,
      "loss": 1.4555,
      "step": 300
    },
    {
      "epoch": 0.9632,
      "grad_norm": 0.2770213186740875,
      "learning_rate": 3.0638810109626103e-07,
      "loss": 1.4502,
      "step": 301
    },
    {
      "epoch": 0.9664,
      "grad_norm": 0.2544289529323578,
      "learning_rate": 2.532582468677214e-07,
      "loss": 1.4325,
      "step": 302
    },
    {
      "epoch": 0.9696,
      "grad_norm": 0.27104616165161133,
      "learning_rate": 2.0517211914545254e-07,
      "loss": 1.5318,
      "step": 303
    },
    {
      "epoch": 0.9728,
      "grad_norm": 0.28957995772361755,
      "learning_rate": 1.6213459328950352e-07,
      "loss": 1.4735,
      "step": 304
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.2612449824810028,
      "learning_rate": 1.2415003279186987e-07,
      "loss": 1.4385,
      "step": 305
    },
    {
      "epoch": 0.9792,
      "grad_norm": 0.2711997628211975,
      "learning_rate": 9.12222888341252e-08,
      "loss": 1.4987,
      "step": 306
    },
    {
      "epoch": 0.9824,
      "grad_norm": 0.25671467185020447,
      "learning_rate": 6.335469989692256e-08,
      "loss": 1.382,
      "step": 307
    },
    {
      "epoch": 0.9856,
      "grad_norm": 0.2655867338180542,
      "learning_rate": 4.055009142152067e-08,
      "loss": 1.4042,
      "step": 308
    },
    {
      "epoch": 0.9888,
      "grad_norm": 0.2655256688594818,
      "learning_rate": 2.2810775523329773e-08,
      "loss": 1.4698,
      "step": 309
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.25174427032470703,
      "learning_rate": 1.0138550757493592e-08,
      "loss": 1.4293,
      "step": 310
    },
    {
      "epoch": 0.9952,
      "grad_norm": 0.24756672978401184,
      "learning_rate": 2.534701936512951e-09,
      "loss": 1.4649,
      "step": 311
    },
    {
      "epoch": 0.9984,
      "grad_norm": 0.27842918038368225,
      "learning_rate": 0.0,
      "loss": 1.5066,
      "step": 312
    }
  ],
  "logging_steps": 1,
  "max_steps": 312,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.8822979421650944e+17,
  "train_batch_size": 12,
  "trial_name": null,
  "trial_params": null
}
