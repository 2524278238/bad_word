{
  "best_metric": 1.4672603607177734,
  "best_model_checkpoint": "/public/home/xiangyuduan/lyt/bad_word/train/models_trilen_lama2/checkpoint-200",
  "epoch": 0.64,
  "eval_steps": 200,
  "global_step": 200,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0032,
      "grad_norm": 0.22593392431735992,
      "learning_rate": 9.999746529806349e-05,
      "loss": 1.925,
      "step": 1
    },
    {
      "epoch": 0.0064,
      "grad_norm": 0.25497129559516907,
      "learning_rate": 9.998986144924251e-05,
      "loss": 1.9433,
      "step": 2
    },
    {
      "epoch": 0.0096,
      "grad_norm": 0.30361831188201904,
      "learning_rate": 9.997718922447667e-05,
      "loss": 1.9245,
      "step": 3
    },
    {
      "epoch": 0.0128,
      "grad_norm": 0.41047248244285583,
      "learning_rate": 9.995944990857849e-05,
      "loss": 1.9035,
      "step": 4
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.47522902488708496,
      "learning_rate": 9.993664530010308e-05,
      "loss": 1.8737,
      "step": 5
    },
    {
      "epoch": 0.0192,
      "grad_norm": 0.49346479773521423,
      "learning_rate": 9.990877771116589e-05,
      "loss": 1.7374,
      "step": 6
    },
    {
      "epoch": 0.0224,
      "grad_norm": 0.5227760076522827,
      "learning_rate": 9.987584996720814e-05,
      "loss": 1.7678,
      "step": 7
    },
    {
      "epoch": 0.0256,
      "grad_norm": 0.5301647186279297,
      "learning_rate": 9.983786540671051e-05,
      "loss": 1.7387,
      "step": 8
    },
    {
      "epoch": 0.0288,
      "grad_norm": 0.5191665291786194,
      "learning_rate": 9.979482788085454e-05,
      "loss": 1.7512,
      "step": 9
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.42366042733192444,
      "learning_rate": 9.974674175313228e-05,
      "loss": 1.6683,
      "step": 10
    },
    {
      "epoch": 0.0352,
      "grad_norm": 0.49262920022010803,
      "learning_rate": 9.969361189890373e-05,
      "loss": 1.6595,
      "step": 11
    },
    {
      "epoch": 0.0384,
      "grad_norm": 0.5442118644714355,
      "learning_rate": 9.96354437049027e-05,
      "loss": 1.6261,
      "step": 12
    },
    {
      "epoch": 0.0416,
      "grad_norm": 0.5838924050331116,
      "learning_rate": 9.957224306869053e-05,
      "loss": 1.5701,
      "step": 13
    },
    {
      "epoch": 0.0448,
      "grad_norm": 0.5328853130340576,
      "learning_rate": 9.95040163980582e-05,
      "loss": 1.6024,
      "step": 14
    },
    {
      "epoch": 0.048,
      "grad_norm": 0.2894571125507355,
      "learning_rate": 9.943077061037671e-05,
      "loss": 1.6024,
      "step": 15
    },
    {
      "epoch": 0.0512,
      "grad_norm": 0.16700959205627441,
      "learning_rate": 9.935251313189564e-05,
      "loss": 1.6134,
      "step": 16
    },
    {
      "epoch": 0.0544,
      "grad_norm": 0.184756338596344,
      "learning_rate": 9.92692518969903e-05,
      "loss": 1.6206,
      "step": 17
    },
    {
      "epoch": 0.0576,
      "grad_norm": 0.1568620204925537,
      "learning_rate": 9.918099534735718e-05,
      "loss": 1.5461,
      "step": 18
    },
    {
      "epoch": 0.0608,
      "grad_norm": 0.17536252737045288,
      "learning_rate": 9.908775243115821e-05,
      "loss": 1.5173,
      "step": 19
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.16682304441928864,
      "learning_rate": 9.898953260211338e-05,
      "loss": 1.5688,
      "step": 20
    },
    {
      "epoch": 0.0672,
      "grad_norm": 0.14114919304847717,
      "learning_rate": 9.888634581854234e-05,
      "loss": 1.6018,
      "step": 21
    },
    {
      "epoch": 0.0704,
      "grad_norm": 0.15416131913661957,
      "learning_rate": 9.877820254235471e-05,
      "loss": 1.5899,
      "step": 22
    },
    {
      "epoch": 0.0736,
      "grad_norm": 0.13088618218898773,
      "learning_rate": 9.86651137379893e-05,
      "loss": 1.5183,
      "step": 23
    },
    {
      "epoch": 0.0768,
      "grad_norm": 0.14014120399951935,
      "learning_rate": 9.85470908713026e-05,
      "loss": 1.5831,
      "step": 24
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.14078623056411743,
      "learning_rate": 9.842414590840617e-05,
      "loss": 1.5381,
      "step": 25
    },
    {
      "epoch": 0.0832,
      "grad_norm": 0.14172953367233276,
      "learning_rate": 9.829629131445342e-05,
      "loss": 1.5897,
      "step": 26
    },
    {
      "epoch": 0.0864,
      "grad_norm": 0.156127467751503,
      "learning_rate": 9.816354005237583e-05,
      "loss": 1.5713,
      "step": 27
    },
    {
      "epoch": 0.0896,
      "grad_norm": 0.14436744153499603,
      "learning_rate": 9.802590558156862e-05,
      "loss": 1.5673,
      "step": 28
    },
    {
      "epoch": 0.0928,
      "grad_norm": 0.1376125067472458,
      "learning_rate": 9.78834018565262e-05,
      "loss": 1.5699,
      "step": 29
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.14200375974178314,
      "learning_rate": 9.773604332542729e-05,
      "loss": 1.6015,
      "step": 30
    },
    {
      "epoch": 0.0992,
      "grad_norm": 0.1446489542722702,
      "learning_rate": 9.758384492867003e-05,
      "loss": 1.5256,
      "step": 31
    },
    {
      "epoch": 0.1024,
      "grad_norm": 0.16929186880588531,
      "learning_rate": 9.742682209735727e-05,
      "loss": 1.5173,
      "step": 32
    },
    {
      "epoch": 0.1056,
      "grad_norm": 0.1526307463645935,
      "learning_rate": 9.726499075173201e-05,
      "loss": 1.4942,
      "step": 33
    },
    {
      "epoch": 0.1088,
      "grad_norm": 0.16427265107631683,
      "learning_rate": 9.709836729956325e-05,
      "loss": 1.53,
      "step": 34
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.1779160052537918,
      "learning_rate": 9.692696863448245e-05,
      "loss": 1.5346,
      "step": 35
    },
    {
      "epoch": 0.1152,
      "grad_norm": 0.15771278738975525,
      "learning_rate": 9.675081213427076e-05,
      "loss": 1.5719,
      "step": 36
    },
    {
      "epoch": 0.1184,
      "grad_norm": 0.1444624364376068,
      "learning_rate": 9.656991565909704e-05,
      "loss": 1.5387,
      "step": 37
    },
    {
      "epoch": 0.1216,
      "grad_norm": 0.1548173725605011,
      "learning_rate": 9.638429754970715e-05,
      "loss": 1.4301,
      "step": 38
    },
    {
      "epoch": 0.1248,
      "grad_norm": 0.1675691157579422,
      "learning_rate": 9.619397662556435e-05,
      "loss": 1.5176,
      "step": 39
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.1627681851387024,
      "learning_rate": 9.599897218294122e-05,
      "loss": 1.6145,
      "step": 40
    },
    {
      "epoch": 0.1312,
      "grad_norm": 0.1574498414993286,
      "learning_rate": 9.579930399296331e-05,
      "loss": 1.5546,
      "step": 41
    },
    {
      "epoch": 0.1344,
      "grad_norm": 0.15323293209075928,
      "learning_rate": 9.559499229960451e-05,
      "loss": 1.4991,
      "step": 42
    },
    {
      "epoch": 0.1376,
      "grad_norm": 0.1636238545179367,
      "learning_rate": 9.538605781763463e-05,
      "loss": 1.5236,
      "step": 43
    },
    {
      "epoch": 0.1408,
      "grad_norm": 0.15789468586444855,
      "learning_rate": 9.517252173051911e-05,
      "loss": 1.517,
      "step": 44
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.16366241872310638,
      "learning_rate": 9.495440568827129e-05,
      "loss": 1.5168,
      "step": 45
    },
    {
      "epoch": 0.1472,
      "grad_norm": 0.15927372872829437,
      "learning_rate": 9.473173180525737e-05,
      "loss": 1.5669,
      "step": 46
    },
    {
      "epoch": 0.1504,
      "grad_norm": 0.15983909368515015,
      "learning_rate": 9.450452265795423e-05,
      "loss": 1.558,
      "step": 47
    },
    {
      "epoch": 0.1536,
      "grad_norm": 0.16263271868228912,
      "learning_rate": 9.42728012826605e-05,
      "loss": 1.5271,
      "step": 48
    },
    {
      "epoch": 0.1568,
      "grad_norm": 0.15285846590995789,
      "learning_rate": 9.403659117316093e-05,
      "loss": 1.4535,
      "step": 49
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.16123074293136597,
      "learning_rate": 9.37959162783444e-05,
      "loss": 1.596,
      "step": 50
    },
    {
      "epoch": 0.1632,
      "grad_norm": 0.15505282580852509,
      "learning_rate": 9.355080099977578e-05,
      "loss": 1.4691,
      "step": 51
    },
    {
      "epoch": 0.1664,
      "grad_norm": 0.16886840760707855,
      "learning_rate": 9.330127018922194e-05,
      "loss": 1.5206,
      "step": 52
    },
    {
      "epoch": 0.1696,
      "grad_norm": 0.16610585153102875,
      "learning_rate": 9.3047349146132e-05,
      "loss": 1.541,
      "step": 53
    },
    {
      "epoch": 0.1728,
      "grad_norm": 0.17045453190803528,
      "learning_rate": 9.278906361507238e-05,
      "loss": 1.5359,
      "step": 54
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.17552550137043,
      "learning_rate": 9.252643978311649e-05,
      "loss": 1.5404,
      "step": 55
    },
    {
      "epoch": 0.1792,
      "grad_norm": 0.1752474159002304,
      "learning_rate": 9.225950427718975e-05,
      "loss": 1.5911,
      "step": 56
    },
    {
      "epoch": 0.1824,
      "grad_norm": 0.16311439871788025,
      "learning_rate": 9.19882841613699e-05,
      "loss": 1.5163,
      "step": 57
    },
    {
      "epoch": 0.1856,
      "grad_norm": 0.16053594648838043,
      "learning_rate": 9.171280693414307e-05,
      "loss": 1.5157,
      "step": 58
    },
    {
      "epoch": 0.1888,
      "grad_norm": 0.17182686924934387,
      "learning_rate": 9.143310052561571e-05,
      "loss": 1.4894,
      "step": 59
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.1710648238658905,
      "learning_rate": 9.114919329468282e-05,
      "loss": 1.5849,
      "step": 60
    },
    {
      "epoch": 0.1952,
      "grad_norm": 0.16170668601989746,
      "learning_rate": 9.086111402615273e-05,
      "loss": 1.519,
      "step": 61
    },
    {
      "epoch": 0.1984,
      "grad_norm": 0.16781075298786163,
      "learning_rate": 9.056889192782866e-05,
      "loss": 1.5215,
      "step": 62
    },
    {
      "epoch": 0.2016,
      "grad_norm": 0.16868571937084198,
      "learning_rate": 9.02725566275473e-05,
      "loss": 1.5381,
      "step": 63
    },
    {
      "epoch": 0.2048,
      "grad_norm": 0.16545835137367249,
      "learning_rate": 8.997213817017507e-05,
      "loss": 1.492,
      "step": 64
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.18686829507350922,
      "learning_rate": 8.966766701456177e-05,
      "loss": 1.4914,
      "step": 65
    },
    {
      "epoch": 0.2112,
      "grad_norm": 0.17821510136127472,
      "learning_rate": 8.935917403045251e-05,
      "loss": 1.5146,
      "step": 66
    },
    {
      "epoch": 0.2144,
      "grad_norm": 0.16694575548171997,
      "learning_rate": 8.904669049535789e-05,
      "loss": 1.515,
      "step": 67
    },
    {
      "epoch": 0.2176,
      "grad_norm": 0.17953936755657196,
      "learning_rate": 8.873024809138272e-05,
      "loss": 1.5175,
      "step": 68
    },
    {
      "epoch": 0.2208,
      "grad_norm": 0.17907072603702545,
      "learning_rate": 8.840987890201403e-05,
      "loss": 1.5743,
      "step": 69
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.18231512606143951,
      "learning_rate": 8.808561540886796e-05,
      "loss": 1.564,
      "step": 70
    },
    {
      "epoch": 0.2272,
      "grad_norm": 0.19188544154167175,
      "learning_rate": 8.775749048839669e-05,
      "loss": 1.5595,
      "step": 71
    },
    {
      "epoch": 0.2304,
      "grad_norm": 0.18380893766880035,
      "learning_rate": 8.742553740855506e-05,
      "loss": 1.5119,
      "step": 72
    },
    {
      "epoch": 0.2336,
      "grad_norm": 0.19725970923900604,
      "learning_rate": 8.708978982542765e-05,
      "loss": 1.5559,
      "step": 73
    },
    {
      "epoch": 0.2368,
      "grad_norm": 0.21221596002578735,
      "learning_rate": 8.675028177981643e-05,
      "loss": 1.5813,
      "step": 74
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.19300885498523712,
      "learning_rate": 8.640704769378942e-05,
      "loss": 1.5461,
      "step": 75
    },
    {
      "epoch": 0.2432,
      "grad_norm": 0.17915217578411102,
      "learning_rate": 8.606012236719073e-05,
      "loss": 1.5436,
      "step": 76
    },
    {
      "epoch": 0.2464,
      "grad_norm": 0.1918337047100067,
      "learning_rate": 8.570954097411223e-05,
      "loss": 1.5376,
      "step": 77
    },
    {
      "epoch": 0.2496,
      "grad_norm": 0.18808311223983765,
      "learning_rate": 8.535533905932738e-05,
      "loss": 1.5192,
      "step": 78
    },
    {
      "epoch": 0.2528,
      "grad_norm": 0.19626280665397644,
      "learning_rate": 8.499755253468733e-05,
      "loss": 1.4977,
      "step": 79
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.20246021449565887,
      "learning_rate": 8.463621767547998e-05,
      "loss": 1.4911,
      "step": 80
    },
    {
      "epoch": 0.2592,
      "grad_norm": 0.20772980153560638,
      "learning_rate": 8.427137111675199e-05,
      "loss": 1.5333,
      "step": 81
    },
    {
      "epoch": 0.2624,
      "grad_norm": 0.20208153128623962,
      "learning_rate": 8.390304984959454e-05,
      "loss": 1.5882,
      "step": 82
    },
    {
      "epoch": 0.2656,
      "grad_norm": 0.20280690491199493,
      "learning_rate": 8.353129121739281e-05,
      "loss": 1.5216,
      "step": 83
    },
    {
      "epoch": 0.2688,
      "grad_norm": 0.18291312456130981,
      "learning_rate": 8.315613291203976e-05,
      "loss": 1.4779,
      "step": 84
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.1797943413257599,
      "learning_rate": 8.277761297011475e-05,
      "loss": 1.5399,
      "step": 85
    },
    {
      "epoch": 0.2752,
      "grad_norm": 0.18718959391117096,
      "learning_rate": 8.239576976902695e-05,
      "loss": 1.5044,
      "step": 86
    },
    {
      "epoch": 0.2784,
      "grad_norm": 0.2050008326768875,
      "learning_rate": 8.201064202312441e-05,
      "loss": 1.4653,
      "step": 87
    },
    {
      "epoch": 0.2816,
      "grad_norm": 0.18374162912368774,
      "learning_rate": 8.162226877976887e-05,
      "loss": 1.472,
      "step": 88
    },
    {
      "epoch": 0.2848,
      "grad_norm": 0.18149255216121674,
      "learning_rate": 8.123068941537682e-05,
      "loss": 1.5277,
      "step": 89
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.1848534345626831,
      "learning_rate": 8.083594363142717e-05,
      "loss": 1.4511,
      "step": 90
    },
    {
      "epoch": 0.2912,
      "grad_norm": 0.19183681905269623,
      "learning_rate": 8.043807145043604e-05,
      "loss": 1.4717,
      "step": 91
    },
    {
      "epoch": 0.2944,
      "grad_norm": 0.19521771371364594,
      "learning_rate": 8.003711321189895e-05,
      "loss": 1.4826,
      "step": 92
    },
    {
      "epoch": 0.2976,
      "grad_norm": 0.18898427486419678,
      "learning_rate": 7.963310956820085e-05,
      "loss": 1.4878,
      "step": 93
    },
    {
      "epoch": 0.3008,
      "grad_norm": 0.18413718044757843,
      "learning_rate": 7.922610148049445e-05,
      "loss": 1.4926,
      "step": 94
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.18856607377529144,
      "learning_rate": 7.881613021454727e-05,
      "loss": 1.3823,
      "step": 95
    },
    {
      "epoch": 0.3072,
      "grad_norm": 0.1984027773141861,
      "learning_rate": 7.840323733655778e-05,
      "loss": 1.4737,
      "step": 96
    },
    {
      "epoch": 0.3104,
      "grad_norm": 0.21438926458358765,
      "learning_rate": 7.798746470894111e-05,
      "loss": 1.505,
      "step": 97
    },
    {
      "epoch": 0.3136,
      "grad_norm": 0.2030361443758011,
      "learning_rate": 7.756885448608459e-05,
      "loss": 1.5145,
      "step": 98
    },
    {
      "epoch": 0.3168,
      "grad_norm": 0.1957009881734848,
      "learning_rate": 7.714744911007394e-05,
      "loss": 1.4952,
      "step": 99
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.20878058671951294,
      "learning_rate": 7.672329130639005e-05,
      "loss": 1.5249,
      "step": 100
    },
    {
      "epoch": 0.3232,
      "grad_norm": 0.21048174798488617,
      "learning_rate": 7.62964240795772e-05,
      "loss": 1.4574,
      "step": 101
    },
    {
      "epoch": 0.3264,
      "grad_norm": 0.2128075808286667,
      "learning_rate": 7.586689070888284e-05,
      "loss": 1.5246,
      "step": 102
    },
    {
      "epoch": 0.3296,
      "grad_norm": 0.20880310237407684,
      "learning_rate": 7.543473474386961e-05,
      "loss": 1.4444,
      "step": 103
    },
    {
      "epoch": 0.3328,
      "grad_norm": 0.20017577707767487,
      "learning_rate": 7.500000000000001e-05,
      "loss": 1.5681,
      "step": 104
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.2040296047925949,
      "learning_rate": 7.456273055419388e-05,
      "loss": 1.4621,
      "step": 105
    },
    {
      "epoch": 0.3392,
      "grad_norm": 0.20936132967472076,
      "learning_rate": 7.412297074035967e-05,
      "loss": 1.4589,
      "step": 106
    },
    {
      "epoch": 0.3424,
      "grad_norm": 0.1953127086162567,
      "learning_rate": 7.368076514489947e-05,
      "loss": 1.4487,
      "step": 107
    },
    {
      "epoch": 0.3456,
      "grad_norm": 0.2107814997434616,
      "learning_rate": 7.323615860218843e-05,
      "loss": 1.4724,
      "step": 108
    },
    {
      "epoch": 0.3488,
      "grad_norm": 0.20714403688907623,
      "learning_rate": 7.278919619002916e-05,
      "loss": 1.5222,
      "step": 109
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.32482364773750305,
      "learning_rate": 7.233992322508129e-05,
      "loss": 1.525,
      "step": 110
    },
    {
      "epoch": 0.3552,
      "grad_norm": 0.2211877852678299,
      "learning_rate": 7.188838525826702e-05,
      "loss": 1.4508,
      "step": 111
    },
    {
      "epoch": 0.3584,
      "grad_norm": 0.2370341569185257,
      "learning_rate": 7.143462807015271e-05,
      "loss": 1.4739,
      "step": 112
    },
    {
      "epoch": 0.3616,
      "grad_norm": 0.2018561214208603,
      "learning_rate": 7.097869766630729e-05,
      "loss": 1.4811,
      "step": 113
    },
    {
      "epoch": 0.3648,
      "grad_norm": 0.22146813571453094,
      "learning_rate": 7.052064027263786e-05,
      "loss": 1.507,
      "step": 114
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.222476989030838,
      "learning_rate": 7.006050233070289e-05,
      "loss": 1.5267,
      "step": 115
    },
    {
      "epoch": 0.3712,
      "grad_norm": 0.2279663234949112,
      "learning_rate": 6.959833049300377e-05,
      "loss": 1.4952,
      "step": 116
    },
    {
      "epoch": 0.3744,
      "grad_norm": 0.22324524819850922,
      "learning_rate": 6.91341716182545e-05,
      "loss": 1.5437,
      "step": 117
    },
    {
      "epoch": 0.3776,
      "grad_norm": 0.21888333559036255,
      "learning_rate": 6.866807276663106e-05,
      "loss": 1.4928,
      "step": 118
    },
    {
      "epoch": 0.3808,
      "grad_norm": 0.2142038643360138,
      "learning_rate": 6.820008119499992e-05,
      "loss": 1.4577,
      "step": 119
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.22031088173389435,
      "learning_rate": 6.773024435212678e-05,
      "loss": 1.5005,
      "step": 120
    },
    {
      "epoch": 0.3872,
      "grad_norm": 0.2185700237751007,
      "learning_rate": 6.72586098738659e-05,
      "loss": 1.4833,
      "step": 121
    },
    {
      "epoch": 0.3904,
      "grad_norm": 0.22753453254699707,
      "learning_rate": 6.678522557833024e-05,
      "loss": 1.5347,
      "step": 122
    },
    {
      "epoch": 0.3936,
      "grad_norm": 0.21715666353702545,
      "learning_rate": 6.631013946104347e-05,
      "loss": 1.4838,
      "step": 123
    },
    {
      "epoch": 0.3968,
      "grad_norm": 0.21376143395900726,
      "learning_rate": 6.583339969007363e-05,
      "loss": 1.4499,
      "step": 124
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.2176460325717926,
      "learning_rate": 6.535505460114954e-05,
      "loss": 1.4408,
      "step": 125
    },
    {
      "epoch": 0.4032,
      "grad_norm": 0.2165469378232956,
      "learning_rate": 6.487515269276016e-05,
      "loss": 1.5277,
      "step": 126
    },
    {
      "epoch": 0.4064,
      "grad_norm": 0.21848233044147491,
      "learning_rate": 6.439374262123731e-05,
      "loss": 1.4319,
      "step": 127
    },
    {
      "epoch": 0.4096,
      "grad_norm": 0.202084481716156,
      "learning_rate": 6.391087319582264e-05,
      "loss": 1.5107,
      "step": 128
    },
    {
      "epoch": 0.4128,
      "grad_norm": 0.22891871631145477,
      "learning_rate": 6.342659337371885e-05,
      "loss": 1.4899,
      "step": 129
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.23061029613018036,
      "learning_rate": 6.294095225512603e-05,
      "loss": 1.5161,
      "step": 130
    },
    {
      "epoch": 0.4192,
      "grad_norm": 0.2233465313911438,
      "learning_rate": 6.24539990782636e-05,
      "loss": 1.5052,
      "step": 131
    },
    {
      "epoch": 0.4224,
      "grad_norm": 0.22587613761425018,
      "learning_rate": 6.19657832143779e-05,
      "loss": 1.4419,
      "step": 132
    },
    {
      "epoch": 0.4256,
      "grad_norm": 0.21092604100704193,
      "learning_rate": 6.147635416273678e-05,
      "loss": 1.4578,
      "step": 133
    },
    {
      "epoch": 0.4288,
      "grad_norm": 0.23101091384887695,
      "learning_rate": 6.098576154561087e-05,
      "loss": 1.4594,
      "step": 134
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.24888573586940765,
      "learning_rate": 6.049405510324238e-05,
      "loss": 1.4183,
      "step": 135
    },
    {
      "epoch": 0.4352,
      "grad_norm": 0.23933818936347961,
      "learning_rate": 6.0001284688802226e-05,
      "loss": 1.441,
      "step": 136
    },
    {
      "epoch": 0.4384,
      "grad_norm": 0.2479722648859024,
      "learning_rate": 5.950750026333534e-05,
      "loss": 1.5262,
      "step": 137
    },
    {
      "epoch": 0.4416,
      "grad_norm": 0.21473442018032074,
      "learning_rate": 5.90127518906953e-05,
      "loss": 1.4321,
      "step": 138
    },
    {
      "epoch": 0.4448,
      "grad_norm": 0.23519492149353027,
      "learning_rate": 5.851708973246841e-05,
      "loss": 1.4927,
      "step": 139
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.23891808092594147,
      "learning_rate": 5.8020564042888015e-05,
      "loss": 1.4324,
      "step": 140
    },
    {
      "epoch": 0.4512,
      "grad_norm": 0.22714057564735413,
      "learning_rate": 5.752322516373916e-05,
      "loss": 1.4145,
      "step": 141
    },
    {
      "epoch": 0.4544,
      "grad_norm": 0.23910793662071228,
      "learning_rate": 5.702512351925464e-05,
      "loss": 1.4507,
      "step": 142
    },
    {
      "epoch": 0.4576,
      "grad_norm": 0.23398970067501068,
      "learning_rate": 5.6526309611002594e-05,
      "loss": 1.5496,
      "step": 143
    },
    {
      "epoch": 0.4608,
      "grad_norm": 0.20416565239429474,
      "learning_rate": 5.602683401276615e-05,
      "loss": 1.4079,
      "step": 144
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.2394026815891266,
      "learning_rate": 5.5526747365416e-05,
      "loss": 1.4926,
      "step": 145
    },
    {
      "epoch": 0.4672,
      "grad_norm": 0.21432876586914062,
      "learning_rate": 5.502610037177586e-05,
      "loss": 1.429,
      "step": 146
    },
    {
      "epoch": 0.4704,
      "grad_norm": 0.2459411770105362,
      "learning_rate": 5.45249437914819e-05,
      "loss": 1.5117,
      "step": 147
    },
    {
      "epoch": 0.4736,
      "grad_norm": 0.22080062329769135,
      "learning_rate": 5.402332843583631e-05,
      "loss": 1.4916,
      "step": 148
    },
    {
      "epoch": 0.4768,
      "grad_norm": 0.22883746027946472,
      "learning_rate": 5.35213051626556e-05,
      "loss": 1.4111,
      "step": 149
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.22886891663074493,
      "learning_rate": 5.3018924871114305e-05,
      "loss": 1.5179,
      "step": 150
    },
    {
      "epoch": 0.4832,
      "grad_norm": 0.24306248128414154,
      "learning_rate": 5.2516238496584335e-05,
      "loss": 1.5725,
      "step": 151
    },
    {
      "epoch": 0.4864,
      "grad_norm": 0.22616137564182281,
      "learning_rate": 5.201329700547076e-05,
      "loss": 1.4687,
      "step": 152
    },
    {
      "epoch": 0.4896,
      "grad_norm": 0.23094163835048676,
      "learning_rate": 5.151015139004445e-05,
      "loss": 1.4509,
      "step": 153
    },
    {
      "epoch": 0.4928,
      "grad_norm": 0.22598963975906372,
      "learning_rate": 5.100685266327202e-05,
      "loss": 1.4055,
      "step": 154
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.24122671782970428,
      "learning_rate": 5.0503451853643776e-05,
      "loss": 1.5178,
      "step": 155
    },
    {
      "epoch": 0.4992,
      "grad_norm": 0.24888333678245544,
      "learning_rate": 5e-05,
      "loss": 1.5082,
      "step": 156
    },
    {
      "epoch": 0.5024,
      "grad_norm": 0.24052703380584717,
      "learning_rate": 4.949654814635623e-05,
      "loss": 1.5261,
      "step": 157
    },
    {
      "epoch": 0.5056,
      "grad_norm": 0.239439457654953,
      "learning_rate": 4.899314733672799e-05,
      "loss": 1.4321,
      "step": 158
    },
    {
      "epoch": 0.5088,
      "grad_norm": 0.22821840643882751,
      "learning_rate": 4.848984860995557e-05,
      "loss": 1.3868,
      "step": 159
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.22580009698867798,
      "learning_rate": 4.798670299452926e-05,
      "loss": 1.4541,
      "step": 160
    },
    {
      "epoch": 0.5152,
      "grad_norm": 0.25823017954826355,
      "learning_rate": 4.748376150341566e-05,
      "loss": 1.5128,
      "step": 161
    },
    {
      "epoch": 0.5184,
      "grad_norm": 0.2459440678358078,
      "learning_rate": 4.6981075128885693e-05,
      "loss": 1.4833,
      "step": 162
    },
    {
      "epoch": 0.5216,
      "grad_norm": 0.2299950122833252,
      "learning_rate": 4.6478694837344404e-05,
      "loss": 1.4959,
      "step": 163
    },
    {
      "epoch": 0.5248,
      "grad_norm": 0.2217624932527542,
      "learning_rate": 4.597667156416371e-05,
      "loss": 1.4817,
      "step": 164
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.24887384474277496,
      "learning_rate": 4.547505620851811e-05,
      "loss": 1.4753,
      "step": 165
    },
    {
      "epoch": 0.5312,
      "grad_norm": 0.2386995255947113,
      "learning_rate": 4.4973899628224154e-05,
      "loss": 1.4689,
      "step": 166
    },
    {
      "epoch": 0.5344,
      "grad_norm": 0.23668792843818665,
      "learning_rate": 4.4473252634584015e-05,
      "loss": 1.4825,
      "step": 167
    },
    {
      "epoch": 0.5376,
      "grad_norm": 0.2386280745267868,
      "learning_rate": 4.397316598723385e-05,
      "loss": 1.4614,
      "step": 168
    },
    {
      "epoch": 0.5408,
      "grad_norm": 0.22242607176303864,
      "learning_rate": 4.347369038899744e-05,
      "loss": 1.4587,
      "step": 169
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.2444268763065338,
      "learning_rate": 4.297487648074538e-05,
      "loss": 1.5169,
      "step": 170
    },
    {
      "epoch": 0.5472,
      "grad_norm": 0.25807464122772217,
      "learning_rate": 4.2476774836260845e-05,
      "loss": 1.39,
      "step": 171
    },
    {
      "epoch": 0.5504,
      "grad_norm": 0.23993034660816193,
      "learning_rate": 4.197943595711198e-05,
      "loss": 1.4558,
      "step": 172
    },
    {
      "epoch": 0.5536,
      "grad_norm": 0.2313421368598938,
      "learning_rate": 4.1482910267531585e-05,
      "loss": 1.5258,
      "step": 173
    },
    {
      "epoch": 0.5568,
      "grad_norm": 0.24976353347301483,
      "learning_rate": 4.0987248109304714e-05,
      "loss": 1.4089,
      "step": 174
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.2396242916584015,
      "learning_rate": 4.049249973666467e-05,
      "loss": 1.4876,
      "step": 175
    },
    {
      "epoch": 0.5632,
      "grad_norm": 0.24623340368270874,
      "learning_rate": 3.9998715311197785e-05,
      "loss": 1.4859,
      "step": 176
    },
    {
      "epoch": 0.5664,
      "grad_norm": 0.256483793258667,
      "learning_rate": 3.950594489675763e-05,
      "loss": 1.4566,
      "step": 177
    },
    {
      "epoch": 0.5696,
      "grad_norm": 0.24051989614963531,
      "learning_rate": 3.901423845438916e-05,
      "loss": 1.5357,
      "step": 178
    },
    {
      "epoch": 0.5728,
      "grad_norm": 0.2609058916568756,
      "learning_rate": 3.852364583726324e-05,
      "loss": 1.4261,
      "step": 179
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.23997069895267487,
      "learning_rate": 3.803421678562213e-05,
      "loss": 1.4952,
      "step": 180
    },
    {
      "epoch": 0.5792,
      "grad_norm": 0.23558861017227173,
      "learning_rate": 3.754600092173641e-05,
      "loss": 1.4587,
      "step": 181
    },
    {
      "epoch": 0.5824,
      "grad_norm": 0.23973232507705688,
      "learning_rate": 3.705904774487396e-05,
      "loss": 1.5583,
      "step": 182
    },
    {
      "epoch": 0.5856,
      "grad_norm": 0.24785520136356354,
      "learning_rate": 3.657340662628116e-05,
      "loss": 1.4178,
      "step": 183
    },
    {
      "epoch": 0.5888,
      "grad_norm": 0.25010424852371216,
      "learning_rate": 3.608912680417737e-05,
      "loss": 1.4348,
      "step": 184
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.2511488199234009,
      "learning_rate": 3.5606257378762696e-05,
      "loss": 1.5101,
      "step": 185
    },
    {
      "epoch": 0.5952,
      "grad_norm": 0.2455495297908783,
      "learning_rate": 3.512484730723986e-05,
      "loss": 1.4403,
      "step": 186
    },
    {
      "epoch": 0.5984,
      "grad_norm": 0.24979116022586823,
      "learning_rate": 3.464494539885047e-05,
      "loss": 1.4052,
      "step": 187
    },
    {
      "epoch": 0.6016,
      "grad_norm": 0.2368009239435196,
      "learning_rate": 3.4166600309926387e-05,
      "loss": 1.4913,
      "step": 188
    },
    {
      "epoch": 0.6048,
      "grad_norm": 0.25149914622306824,
      "learning_rate": 3.368986053895655e-05,
      "loss": 1.4712,
      "step": 189
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.2440742552280426,
      "learning_rate": 3.3214774421669774e-05,
      "loss": 1.3749,
      "step": 190
    },
    {
      "epoch": 0.6112,
      "grad_norm": 0.2386358380317688,
      "learning_rate": 3.2741390126134106e-05,
      "loss": 1.4104,
      "step": 191
    },
    {
      "epoch": 0.6144,
      "grad_norm": 0.25337132811546326,
      "learning_rate": 3.226975564787322e-05,
      "loss": 1.4674,
      "step": 192
    },
    {
      "epoch": 0.6176,
      "grad_norm": 0.2432161271572113,
      "learning_rate": 3.179991880500009e-05,
      "loss": 1.3851,
      "step": 193
    },
    {
      "epoch": 0.6208,
      "grad_norm": 0.2497641146183014,
      "learning_rate": 3.133192723336895e-05,
      "loss": 1.478,
      "step": 194
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.25351008772850037,
      "learning_rate": 3.086582838174551e-05,
      "loss": 1.4887,
      "step": 195
    },
    {
      "epoch": 0.6272,
      "grad_norm": 0.2386268526315689,
      "learning_rate": 3.0401669506996256e-05,
      "loss": 1.5024,
      "step": 196
    },
    {
      "epoch": 0.6304,
      "grad_norm": 0.26167598366737366,
      "learning_rate": 2.9939497669297112e-05,
      "loss": 1.5306,
      "step": 197
    },
    {
      "epoch": 0.6336,
      "grad_norm": 0.2525985836982727,
      "learning_rate": 2.9479359727362173e-05,
      "loss": 1.4828,
      "step": 198
    },
    {
      "epoch": 0.6368,
      "grad_norm": 0.24866130948066711,
      "learning_rate": 2.9021302333692734e-05,
      "loss": 1.5163,
      "step": 199
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.26124536991119385,
      "learning_rate": 2.8565371929847284e-05,
      "loss": 1.5212,
      "step": 200
    },
    {
      "epoch": 0.64,
      "eval_loss": 1.4672603607177734,
      "eval_runtime": 8.0433,
      "eval_samples_per_second": 23.249,
      "eval_steps_per_second": 2.984,
      "step": 200
    }
  ],
  "logging_steps": 1,
  "max_steps": 312,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.2050657629913088e+17,
  "train_batch_size": 12,
  "trial_name": null,
  "trial_params": null
}
