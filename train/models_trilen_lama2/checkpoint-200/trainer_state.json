{
  "best_metric": 1.4843626022338867,
  "best_model_checkpoint": "/public/home/xiangyuduan/lyt/bad_word/train/models_trilen_lama2/checkpoint-200",
  "epoch": 0.64,
  "eval_steps": 200,
  "global_step": 200,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0032,
      "grad_norm": 0.1893470138311386,
      "learning_rate": 9.999746529806349e-05,
      "loss": 1.8552,
      "step": 1
    },
    {
      "epoch": 0.0064,
      "grad_norm": 0.23851817846298218,
      "learning_rate": 9.998986144924251e-05,
      "loss": 1.8749,
      "step": 2
    },
    {
      "epoch": 0.0096,
      "grad_norm": 0.28773897886276245,
      "learning_rate": 9.997718922447667e-05,
      "loss": 1.8624,
      "step": 3
    },
    {
      "epoch": 0.0128,
      "grad_norm": 0.40631234645843506,
      "learning_rate": 9.995944990857849e-05,
      "loss": 1.8352,
      "step": 4
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.4425086975097656,
      "learning_rate": 9.993664530010308e-05,
      "loss": 1.8204,
      "step": 5
    },
    {
      "epoch": 0.0192,
      "grad_norm": 0.4686996340751648,
      "learning_rate": 9.990877771116589e-05,
      "loss": 1.6871,
      "step": 6
    },
    {
      "epoch": 0.0224,
      "grad_norm": 0.5092803239822388,
      "learning_rate": 9.987584996720814e-05,
      "loss": 1.7179,
      "step": 7
    },
    {
      "epoch": 0.0256,
      "grad_norm": 0.49676936864852905,
      "learning_rate": 9.983786540671051e-05,
      "loss": 1.6916,
      "step": 8
    },
    {
      "epoch": 0.0288,
      "grad_norm": 0.4800097644329071,
      "learning_rate": 9.979482788085454e-05,
      "loss": 1.6997,
      "step": 9
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.39038023352622986,
      "learning_rate": 9.974674175313228e-05,
      "loss": 1.6231,
      "step": 10
    },
    {
      "epoch": 0.0352,
      "grad_norm": 0.46380066871643066,
      "learning_rate": 9.969361189890373e-05,
      "loss": 1.6188,
      "step": 11
    },
    {
      "epoch": 0.0384,
      "grad_norm": 0.5063058733940125,
      "learning_rate": 9.96354437049027e-05,
      "loss": 1.588,
      "step": 12
    },
    {
      "epoch": 0.0416,
      "grad_norm": 0.566922128200531,
      "learning_rate": 9.957224306869053e-05,
      "loss": 1.5475,
      "step": 13
    },
    {
      "epoch": 0.0448,
      "grad_norm": 0.6105808615684509,
      "learning_rate": 9.95040163980582e-05,
      "loss": 1.5816,
      "step": 14
    },
    {
      "epoch": 0.048,
      "grad_norm": 0.5334651470184326,
      "learning_rate": 9.943077061037671e-05,
      "loss": 1.5823,
      "step": 15
    },
    {
      "epoch": 0.0512,
      "grad_norm": 0.2815758287906647,
      "learning_rate": 9.935251313189564e-05,
      "loss": 1.5933,
      "step": 16
    },
    {
      "epoch": 0.0544,
      "grad_norm": 0.36063599586486816,
      "learning_rate": 9.92692518969903e-05,
      "loss": 1.6012,
      "step": 17
    },
    {
      "epoch": 0.0576,
      "grad_norm": 0.1453855186700821,
      "learning_rate": 9.918099534735718e-05,
      "loss": 1.526,
      "step": 18
    },
    {
      "epoch": 0.0608,
      "grad_norm": 0.1515911966562271,
      "learning_rate": 9.908775243115821e-05,
      "loss": 1.5046,
      "step": 19
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.14417578279972076,
      "learning_rate": 9.898953260211338e-05,
      "loss": 1.5596,
      "step": 20
    },
    {
      "epoch": 0.0672,
      "grad_norm": 0.12809401750564575,
      "learning_rate": 9.888634581854234e-05,
      "loss": 1.5877,
      "step": 21
    },
    {
      "epoch": 0.0704,
      "grad_norm": 0.14209283888339996,
      "learning_rate": 9.877820254235471e-05,
      "loss": 1.5771,
      "step": 22
    },
    {
      "epoch": 0.0736,
      "grad_norm": 0.12236630171537399,
      "learning_rate": 9.86651137379893e-05,
      "loss": 1.506,
      "step": 23
    },
    {
      "epoch": 0.0768,
      "grad_norm": 0.13456524908542633,
      "learning_rate": 9.85470908713026e-05,
      "loss": 1.576,
      "step": 24
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.13283759355545044,
      "learning_rate": 9.842414590840617e-05,
      "loss": 1.5215,
      "step": 25
    },
    {
      "epoch": 0.0832,
      "grad_norm": 0.13401800394058228,
      "learning_rate": 9.829629131445342e-05,
      "loss": 1.5821,
      "step": 26
    },
    {
      "epoch": 0.0864,
      "grad_norm": 0.155936136841774,
      "learning_rate": 9.816354005237583e-05,
      "loss": 1.5619,
      "step": 27
    },
    {
      "epoch": 0.0896,
      "grad_norm": 0.14210978150367737,
      "learning_rate": 9.802590558156862e-05,
      "loss": 1.5586,
      "step": 28
    },
    {
      "epoch": 0.0928,
      "grad_norm": 0.13203802704811096,
      "learning_rate": 9.78834018565262e-05,
      "loss": 1.563,
      "step": 29
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.13929888606071472,
      "learning_rate": 9.773604332542729e-05,
      "loss": 1.5957,
      "step": 30
    },
    {
      "epoch": 0.0992,
      "grad_norm": 0.13858340680599213,
      "learning_rate": 9.758384492867003e-05,
      "loss": 1.5247,
      "step": 31
    },
    {
      "epoch": 0.1024,
      "grad_norm": 0.1624964326620102,
      "learning_rate": 9.742682209735727e-05,
      "loss": 1.5144,
      "step": 32
    },
    {
      "epoch": 0.1056,
      "grad_norm": 0.145760640501976,
      "learning_rate": 9.726499075173201e-05,
      "loss": 1.4949,
      "step": 33
    },
    {
      "epoch": 0.1088,
      "grad_norm": 0.15663322806358337,
      "learning_rate": 9.709836729956325e-05,
      "loss": 1.5288,
      "step": 34
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.16293132305145264,
      "learning_rate": 9.692696863448245e-05,
      "loss": 1.5311,
      "step": 35
    },
    {
      "epoch": 0.1152,
      "grad_norm": 0.1548500657081604,
      "learning_rate": 9.675081213427076e-05,
      "loss": 1.5732,
      "step": 36
    },
    {
      "epoch": 0.1184,
      "grad_norm": 0.14590254426002502,
      "learning_rate": 9.656991565909704e-05,
      "loss": 1.5322,
      "step": 37
    },
    {
      "epoch": 0.1216,
      "grad_norm": 0.1522640734910965,
      "learning_rate": 9.638429754970715e-05,
      "loss": 1.4276,
      "step": 38
    },
    {
      "epoch": 0.1248,
      "grad_norm": 0.16098365187644958,
      "learning_rate": 9.619397662556435e-05,
      "loss": 1.5132,
      "step": 39
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.1565244495868683,
      "learning_rate": 9.599897218294122e-05,
      "loss": 1.6023,
      "step": 40
    },
    {
      "epoch": 0.1312,
      "grad_norm": 0.15415699779987335,
      "learning_rate": 9.579930399296331e-05,
      "loss": 1.5597,
      "step": 41
    },
    {
      "epoch": 0.1344,
      "grad_norm": 0.15235686302185059,
      "learning_rate": 9.559499229960451e-05,
      "loss": 1.4969,
      "step": 42
    },
    {
      "epoch": 0.1376,
      "grad_norm": 0.16721989214420319,
      "learning_rate": 9.538605781763463e-05,
      "loss": 1.5241,
      "step": 43
    },
    {
      "epoch": 0.1408,
      "grad_norm": 0.15690214931964874,
      "learning_rate": 9.517252173051911e-05,
      "loss": 1.5153,
      "step": 44
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.161863774061203,
      "learning_rate": 9.495440568827129e-05,
      "loss": 1.5191,
      "step": 45
    },
    {
      "epoch": 0.1472,
      "grad_norm": 0.15864412486553192,
      "learning_rate": 9.473173180525737e-05,
      "loss": 1.5669,
      "step": 46
    },
    {
      "epoch": 0.1504,
      "grad_norm": 0.15633703768253326,
      "learning_rate": 9.450452265795423e-05,
      "loss": 1.5583,
      "step": 47
    },
    {
      "epoch": 0.1536,
      "grad_norm": 0.1632051318883896,
      "learning_rate": 9.42728012826605e-05,
      "loss": 1.5254,
      "step": 48
    },
    {
      "epoch": 0.1568,
      "grad_norm": 0.15084590017795563,
      "learning_rate": 9.403659117316093e-05,
      "loss": 1.4548,
      "step": 49
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.15885688364505768,
      "learning_rate": 9.37959162783444e-05,
      "loss": 1.5985,
      "step": 50
    },
    {
      "epoch": 0.1632,
      "grad_norm": 0.15628089010715485,
      "learning_rate": 9.355080099977578e-05,
      "loss": 1.4717,
      "step": 51
    },
    {
      "epoch": 0.1664,
      "grad_norm": 0.17013083398342133,
      "learning_rate": 9.330127018922194e-05,
      "loss": 1.5268,
      "step": 52
    },
    {
      "epoch": 0.1696,
      "grad_norm": 0.16618241369724274,
      "learning_rate": 9.3047349146132e-05,
      "loss": 1.5423,
      "step": 53
    },
    {
      "epoch": 0.1728,
      "grad_norm": 0.1638496220111847,
      "learning_rate": 9.278906361507238e-05,
      "loss": 1.5347,
      "step": 54
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.17095313966274261,
      "learning_rate": 9.252643978311649e-05,
      "loss": 1.5422,
      "step": 55
    },
    {
      "epoch": 0.1792,
      "grad_norm": 0.17273126542568207,
      "learning_rate": 9.225950427718975e-05,
      "loss": 1.5923,
      "step": 56
    },
    {
      "epoch": 0.1824,
      "grad_norm": 0.16046597063541412,
      "learning_rate": 9.19882841613699e-05,
      "loss": 1.5188,
      "step": 57
    },
    {
      "epoch": 0.1856,
      "grad_norm": 0.15751716494560242,
      "learning_rate": 9.171280693414307e-05,
      "loss": 1.5205,
      "step": 58
    },
    {
      "epoch": 0.1888,
      "grad_norm": 0.1715632826089859,
      "learning_rate": 9.143310052561571e-05,
      "loss": 1.4912,
      "step": 59
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.16766852140426636,
      "learning_rate": 9.114919329468282e-05,
      "loss": 1.5853,
      "step": 60
    },
    {
      "epoch": 0.1952,
      "grad_norm": 0.16007019579410553,
      "learning_rate": 9.086111402615273e-05,
      "loss": 1.518,
      "step": 61
    },
    {
      "epoch": 0.1984,
      "grad_norm": 0.16399691998958588,
      "learning_rate": 9.056889192782866e-05,
      "loss": 1.5207,
      "step": 62
    },
    {
      "epoch": 0.2016,
      "grad_norm": 0.16831538081169128,
      "learning_rate": 9.02725566275473e-05,
      "loss": 1.5341,
      "step": 63
    },
    {
      "epoch": 0.2048,
      "grad_norm": 0.16358087956905365,
      "learning_rate": 8.997213817017507e-05,
      "loss": 1.4932,
      "step": 64
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.18055525422096252,
      "learning_rate": 8.966766701456177e-05,
      "loss": 1.4916,
      "step": 65
    },
    {
      "epoch": 0.2112,
      "grad_norm": 0.1766657680273056,
      "learning_rate": 8.935917403045251e-05,
      "loss": 1.514,
      "step": 66
    },
    {
      "epoch": 0.2144,
      "grad_norm": 0.16910511255264282,
      "learning_rate": 8.904669049535789e-05,
      "loss": 1.5171,
      "step": 67
    },
    {
      "epoch": 0.2176,
      "grad_norm": 0.18042317032814026,
      "learning_rate": 8.873024809138272e-05,
      "loss": 1.5178,
      "step": 68
    },
    {
      "epoch": 0.2208,
      "grad_norm": 0.17987783253192902,
      "learning_rate": 8.840987890201403e-05,
      "loss": 1.5755,
      "step": 69
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.18168790638446808,
      "learning_rate": 8.808561540886796e-05,
      "loss": 1.5668,
      "step": 70
    },
    {
      "epoch": 0.2272,
      "grad_norm": 0.1931934654712677,
      "learning_rate": 8.775749048839669e-05,
      "loss": 1.5615,
      "step": 71
    },
    {
      "epoch": 0.2304,
      "grad_norm": 0.18608291447162628,
      "learning_rate": 8.742553740855506e-05,
      "loss": 1.5177,
      "step": 72
    },
    {
      "epoch": 0.2336,
      "grad_norm": 0.19495582580566406,
      "learning_rate": 8.708978982542765e-05,
      "loss": 1.5568,
      "step": 73
    },
    {
      "epoch": 0.2368,
      "grad_norm": 0.21344445645809174,
      "learning_rate": 8.675028177981643e-05,
      "loss": 1.5816,
      "step": 74
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.19072756171226501,
      "learning_rate": 8.640704769378942e-05,
      "loss": 1.5464,
      "step": 75
    },
    {
      "epoch": 0.2432,
      "grad_norm": 0.1801251620054245,
      "learning_rate": 8.606012236719073e-05,
      "loss": 1.5459,
      "step": 76
    },
    {
      "epoch": 0.2464,
      "grad_norm": 0.19663988053798676,
      "learning_rate": 8.570954097411223e-05,
      "loss": 1.5408,
      "step": 77
    },
    {
      "epoch": 0.2496,
      "grad_norm": 0.1897640973329544,
      "learning_rate": 8.535533905932738e-05,
      "loss": 1.5228,
      "step": 78
    },
    {
      "epoch": 0.2528,
      "grad_norm": 0.1992996335029602,
      "learning_rate": 8.499755253468733e-05,
      "loss": 1.4991,
      "step": 79
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.20133261382579803,
      "learning_rate": 8.463621767547998e-05,
      "loss": 1.4968,
      "step": 80
    },
    {
      "epoch": 0.2592,
      "grad_norm": 0.20051196217536926,
      "learning_rate": 8.427137111675199e-05,
      "loss": 1.5326,
      "step": 81
    },
    {
      "epoch": 0.2624,
      "grad_norm": 0.19859090447425842,
      "learning_rate": 8.390304984959454e-05,
      "loss": 1.5909,
      "step": 82
    },
    {
      "epoch": 0.2656,
      "grad_norm": 0.2051089107990265,
      "learning_rate": 8.353129121739281e-05,
      "loss": 1.5267,
      "step": 83
    },
    {
      "epoch": 0.2688,
      "grad_norm": 0.185085266828537,
      "learning_rate": 8.315613291203976e-05,
      "loss": 1.48,
      "step": 84
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.18022018671035767,
      "learning_rate": 8.277761297011475e-05,
      "loss": 1.5437,
      "step": 85
    },
    {
      "epoch": 0.2752,
      "grad_norm": 0.18693074584007263,
      "learning_rate": 8.239576976902695e-05,
      "loss": 1.5082,
      "step": 86
    },
    {
      "epoch": 0.2784,
      "grad_norm": 0.20396587252616882,
      "learning_rate": 8.201064202312441e-05,
      "loss": 1.4683,
      "step": 87
    },
    {
      "epoch": 0.2816,
      "grad_norm": 0.18644538521766663,
      "learning_rate": 8.162226877976887e-05,
      "loss": 1.4754,
      "step": 88
    },
    {
      "epoch": 0.2848,
      "grad_norm": 0.18112973868846893,
      "learning_rate": 8.123068941537682e-05,
      "loss": 1.5302,
      "step": 89
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.1846984475851059,
      "learning_rate": 8.083594363142717e-05,
      "loss": 1.4536,
      "step": 90
    },
    {
      "epoch": 0.2912,
      "grad_norm": 0.19217489659786224,
      "learning_rate": 8.043807145043604e-05,
      "loss": 1.4775,
      "step": 91
    },
    {
      "epoch": 0.2944,
      "grad_norm": 0.19242143630981445,
      "learning_rate": 8.003711321189895e-05,
      "loss": 1.484,
      "step": 92
    },
    {
      "epoch": 0.2976,
      "grad_norm": 0.1873529851436615,
      "learning_rate": 7.963310956820085e-05,
      "loss": 1.4943,
      "step": 93
    },
    {
      "epoch": 0.3008,
      "grad_norm": 0.1827649027109146,
      "learning_rate": 7.922610148049445e-05,
      "loss": 1.4924,
      "step": 94
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.1870049685239792,
      "learning_rate": 7.881613021454727e-05,
      "loss": 1.3874,
      "step": 95
    },
    {
      "epoch": 0.3072,
      "grad_norm": 0.20014147460460663,
      "learning_rate": 7.840323733655778e-05,
      "loss": 1.4759,
      "step": 96
    },
    {
      "epoch": 0.3104,
      "grad_norm": 0.21479323506355286,
      "learning_rate": 7.798746470894111e-05,
      "loss": 1.5063,
      "step": 97
    },
    {
      "epoch": 0.3136,
      "grad_norm": 0.2004529982805252,
      "learning_rate": 7.756885448608459e-05,
      "loss": 1.5202,
      "step": 98
    },
    {
      "epoch": 0.3168,
      "grad_norm": 0.19767996668815613,
      "learning_rate": 7.714744911007394e-05,
      "loss": 1.5016,
      "step": 99
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.21086488664150238,
      "learning_rate": 7.672329130639005e-05,
      "loss": 1.5345,
      "step": 100
    },
    {
      "epoch": 0.3232,
      "grad_norm": 0.20955905318260193,
      "learning_rate": 7.62964240795772e-05,
      "loss": 1.4634,
      "step": 101
    },
    {
      "epoch": 0.3264,
      "grad_norm": 0.20074018836021423,
      "learning_rate": 7.586689070888284e-05,
      "loss": 1.5247,
      "step": 102
    },
    {
      "epoch": 0.3296,
      "grad_norm": 0.19989849627017975,
      "learning_rate": 7.543473474386961e-05,
      "loss": 1.4455,
      "step": 103
    },
    {
      "epoch": 0.3328,
      "grad_norm": 0.19709569215774536,
      "learning_rate": 7.500000000000001e-05,
      "loss": 1.5706,
      "step": 104
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.20276331901550293,
      "learning_rate": 7.456273055419388e-05,
      "loss": 1.4675,
      "step": 105
    },
    {
      "epoch": 0.3392,
      "grad_norm": 0.20675387978553772,
      "learning_rate": 7.412297074035967e-05,
      "loss": 1.4632,
      "step": 106
    },
    {
      "epoch": 0.3424,
      "grad_norm": 0.19686812162399292,
      "learning_rate": 7.368076514489947e-05,
      "loss": 1.4478,
      "step": 107
    },
    {
      "epoch": 0.3456,
      "grad_norm": 0.2057335078716278,
      "learning_rate": 7.323615860218843e-05,
      "loss": 1.4748,
      "step": 108
    },
    {
      "epoch": 0.3488,
      "grad_norm": 0.20080731809139252,
      "learning_rate": 7.278919619002916e-05,
      "loss": 1.5274,
      "step": 109
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.2020808756351471,
      "learning_rate": 7.233992322508129e-05,
      "loss": 1.5282,
      "step": 110
    },
    {
      "epoch": 0.3552,
      "grad_norm": 0.2219163179397583,
      "learning_rate": 7.188838525826702e-05,
      "loss": 1.4551,
      "step": 111
    },
    {
      "epoch": 0.3584,
      "grad_norm": 0.23977196216583252,
      "learning_rate": 7.143462807015271e-05,
      "loss": 1.4785,
      "step": 112
    },
    {
      "epoch": 0.3616,
      "grad_norm": 0.20076879858970642,
      "learning_rate": 7.097869766630729e-05,
      "loss": 1.485,
      "step": 113
    },
    {
      "epoch": 0.3648,
      "grad_norm": 0.2142629474401474,
      "learning_rate": 7.052064027263786e-05,
      "loss": 1.5097,
      "step": 114
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.21832901239395142,
      "learning_rate": 7.006050233070289e-05,
      "loss": 1.5284,
      "step": 115
    },
    {
      "epoch": 0.3712,
      "grad_norm": 0.2229302078485489,
      "learning_rate": 6.959833049300377e-05,
      "loss": 1.4967,
      "step": 116
    },
    {
      "epoch": 0.3744,
      "grad_norm": 0.2221042513847351,
      "learning_rate": 6.91341716182545e-05,
      "loss": 1.5508,
      "step": 117
    },
    {
      "epoch": 0.3776,
      "grad_norm": 0.21409988403320312,
      "learning_rate": 6.866807276663106e-05,
      "loss": 1.4987,
      "step": 118
    },
    {
      "epoch": 0.3808,
      "grad_norm": 0.21124020218849182,
      "learning_rate": 6.820008119499992e-05,
      "loss": 1.455,
      "step": 119
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.2165650874376297,
      "learning_rate": 6.773024435212678e-05,
      "loss": 1.5034,
      "step": 120
    },
    {
      "epoch": 0.3872,
      "grad_norm": 0.21056510508060455,
      "learning_rate": 6.72586098738659e-05,
      "loss": 1.4906,
      "step": 121
    },
    {
      "epoch": 0.3904,
      "grad_norm": 0.2227218598127365,
      "learning_rate": 6.678522557833024e-05,
      "loss": 1.5346,
      "step": 122
    },
    {
      "epoch": 0.3936,
      "grad_norm": 0.21778137981891632,
      "learning_rate": 6.631013946104347e-05,
      "loss": 1.4871,
      "step": 123
    },
    {
      "epoch": 0.3968,
      "grad_norm": 0.21095556020736694,
      "learning_rate": 6.583339969007363e-05,
      "loss": 1.4528,
      "step": 124
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.21393892168998718,
      "learning_rate": 6.535505460114954e-05,
      "loss": 1.443,
      "step": 125
    },
    {
      "epoch": 0.4032,
      "grad_norm": 0.21449041366577148,
      "learning_rate": 6.487515269276016e-05,
      "loss": 1.528,
      "step": 126
    },
    {
      "epoch": 0.4064,
      "grad_norm": 0.216848224401474,
      "learning_rate": 6.439374262123731e-05,
      "loss": 1.4318,
      "step": 127
    },
    {
      "epoch": 0.4096,
      "grad_norm": 0.1969747245311737,
      "learning_rate": 6.391087319582264e-05,
      "loss": 1.5138,
      "step": 128
    },
    {
      "epoch": 0.4128,
      "grad_norm": 0.22774723172187805,
      "learning_rate": 6.342659337371885e-05,
      "loss": 1.489,
      "step": 129
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.21813207864761353,
      "learning_rate": 6.294095225512603e-05,
      "loss": 1.5216,
      "step": 130
    },
    {
      "epoch": 0.4192,
      "grad_norm": 0.22069184482097626,
      "learning_rate": 6.24539990782636e-05,
      "loss": 1.5076,
      "step": 131
    },
    {
      "epoch": 0.4224,
      "grad_norm": 0.2234964668750763,
      "learning_rate": 6.19657832143779e-05,
      "loss": 1.4434,
      "step": 132
    },
    {
      "epoch": 0.4256,
      "grad_norm": 0.208647221326828,
      "learning_rate": 6.147635416273678e-05,
      "loss": 1.4618,
      "step": 133
    },
    {
      "epoch": 0.4288,
      "grad_norm": 0.22803610563278198,
      "learning_rate": 6.098576154561087e-05,
      "loss": 1.4609,
      "step": 134
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.24249239265918732,
      "learning_rate": 6.049405510324238e-05,
      "loss": 1.4182,
      "step": 135
    },
    {
      "epoch": 0.4352,
      "grad_norm": 0.23520980775356293,
      "learning_rate": 6.0001284688802226e-05,
      "loss": 1.4446,
      "step": 136
    },
    {
      "epoch": 0.4384,
      "grad_norm": 0.2394314557313919,
      "learning_rate": 5.950750026333534e-05,
      "loss": 1.5301,
      "step": 137
    },
    {
      "epoch": 0.4416,
      "grad_norm": 0.21303176879882812,
      "learning_rate": 5.90127518906953e-05,
      "loss": 1.4357,
      "step": 138
    },
    {
      "epoch": 0.4448,
      "grad_norm": 0.22807197272777557,
      "learning_rate": 5.851708973246841e-05,
      "loss": 1.4954,
      "step": 139
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.23839551210403442,
      "learning_rate": 5.8020564042888015e-05,
      "loss": 1.4352,
      "step": 140
    },
    {
      "epoch": 0.4512,
      "grad_norm": 0.22876107692718506,
      "learning_rate": 5.752322516373916e-05,
      "loss": 1.4201,
      "step": 141
    },
    {
      "epoch": 0.4544,
      "grad_norm": 0.23712317645549774,
      "learning_rate": 5.702512351925464e-05,
      "loss": 1.451,
      "step": 142
    },
    {
      "epoch": 0.4576,
      "grad_norm": 0.23030395805835724,
      "learning_rate": 5.6526309611002594e-05,
      "loss": 1.5488,
      "step": 143
    },
    {
      "epoch": 0.4608,
      "grad_norm": 0.2036706954240799,
      "learning_rate": 5.602683401276615e-05,
      "loss": 1.4097,
      "step": 144
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.23618073761463165,
      "learning_rate": 5.5526747365416e-05,
      "loss": 1.4956,
      "step": 145
    },
    {
      "epoch": 0.4672,
      "grad_norm": 0.2122587114572525,
      "learning_rate": 5.502610037177586e-05,
      "loss": 1.4352,
      "step": 146
    },
    {
      "epoch": 0.4704,
      "grad_norm": 0.24899685382843018,
      "learning_rate": 5.45249437914819e-05,
      "loss": 1.5117,
      "step": 147
    },
    {
      "epoch": 0.4736,
      "grad_norm": 0.22075903415679932,
      "learning_rate": 5.402332843583631e-05,
      "loss": 1.4968,
      "step": 148
    },
    {
      "epoch": 0.4768,
      "grad_norm": 0.23112869262695312,
      "learning_rate": 5.35213051626556e-05,
      "loss": 1.4155,
      "step": 149
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.22927765548229218,
      "learning_rate": 5.3018924871114305e-05,
      "loss": 1.5214,
      "step": 150
    },
    {
      "epoch": 0.4832,
      "grad_norm": 0.241519957780838,
      "learning_rate": 5.2516238496584335e-05,
      "loss": 1.572,
      "step": 151
    },
    {
      "epoch": 0.4864,
      "grad_norm": 0.22389160096645355,
      "learning_rate": 5.201329700547076e-05,
      "loss": 1.4714,
      "step": 152
    },
    {
      "epoch": 0.4896,
      "grad_norm": 0.22957095503807068,
      "learning_rate": 5.151015139004445e-05,
      "loss": 1.4471,
      "step": 153
    },
    {
      "epoch": 0.4928,
      "grad_norm": 0.22782355546951294,
      "learning_rate": 5.100685266327202e-05,
      "loss": 1.4097,
      "step": 154
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.24243366718292236,
      "learning_rate": 5.0503451853643776e-05,
      "loss": 1.5255,
      "step": 155
    },
    {
      "epoch": 0.4992,
      "grad_norm": 0.24626174569129944,
      "learning_rate": 5e-05,
      "loss": 1.5051,
      "step": 156
    },
    {
      "epoch": 0.5024,
      "grad_norm": 0.2366359978914261,
      "learning_rate": 4.949654814635623e-05,
      "loss": 1.5287,
      "step": 157
    },
    {
      "epoch": 0.5056,
      "grad_norm": 0.23790434002876282,
      "learning_rate": 4.899314733672799e-05,
      "loss": 1.4372,
      "step": 158
    },
    {
      "epoch": 0.5088,
      "grad_norm": 0.22669357061386108,
      "learning_rate": 4.848984860995557e-05,
      "loss": 1.3897,
      "step": 159
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.22956745326519012,
      "learning_rate": 4.798670299452926e-05,
      "loss": 1.4585,
      "step": 160
    },
    {
      "epoch": 0.5152,
      "grad_norm": 0.25573310256004333,
      "learning_rate": 4.748376150341566e-05,
      "loss": 1.513,
      "step": 161
    },
    {
      "epoch": 0.5184,
      "grad_norm": 0.2455359697341919,
      "learning_rate": 4.6981075128885693e-05,
      "loss": 1.4859,
      "step": 162
    },
    {
      "epoch": 0.5216,
      "grad_norm": 0.22841796278953552,
      "learning_rate": 4.6478694837344404e-05,
      "loss": 1.4977,
      "step": 163
    },
    {
      "epoch": 0.5248,
      "grad_norm": 0.21989193558692932,
      "learning_rate": 4.597667156416371e-05,
      "loss": 1.4816,
      "step": 164
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.2464672029018402,
      "learning_rate": 4.547505620851811e-05,
      "loss": 1.4799,
      "step": 165
    },
    {
      "epoch": 0.5312,
      "grad_norm": 0.23899294435977936,
      "learning_rate": 4.4973899628224154e-05,
      "loss": 1.477,
      "step": 166
    },
    {
      "epoch": 0.5344,
      "grad_norm": 0.23633046448230743,
      "learning_rate": 4.4473252634584015e-05,
      "loss": 1.4849,
      "step": 167
    },
    {
      "epoch": 0.5376,
      "grad_norm": 0.23780705034732819,
      "learning_rate": 4.397316598723385e-05,
      "loss": 1.4674,
      "step": 168
    },
    {
      "epoch": 0.5408,
      "grad_norm": 0.2212069034576416,
      "learning_rate": 4.347369038899744e-05,
      "loss": 1.4602,
      "step": 169
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.24263979494571686,
      "learning_rate": 4.297487648074538e-05,
      "loss": 1.5175,
      "step": 170
    },
    {
      "epoch": 0.5472,
      "grad_norm": 0.25396931171417236,
      "learning_rate": 4.2476774836260845e-05,
      "loss": 1.3961,
      "step": 171
    },
    {
      "epoch": 0.5504,
      "grad_norm": 0.23848912119865417,
      "learning_rate": 4.197943595711198e-05,
      "loss": 1.4626,
      "step": 172
    },
    {
      "epoch": 0.5536,
      "grad_norm": 0.22902154922485352,
      "learning_rate": 4.1482910267531585e-05,
      "loss": 1.5304,
      "step": 173
    },
    {
      "epoch": 0.5568,
      "grad_norm": 0.24747422337532043,
      "learning_rate": 4.0987248109304714e-05,
      "loss": 1.4102,
      "step": 174
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.2378941774368286,
      "learning_rate": 4.049249973666467e-05,
      "loss": 1.4878,
      "step": 175
    },
    {
      "epoch": 0.5632,
      "grad_norm": 0.24377253651618958,
      "learning_rate": 3.9998715311197785e-05,
      "loss": 1.4874,
      "step": 176
    },
    {
      "epoch": 0.5664,
      "grad_norm": 0.2588345408439636,
      "learning_rate": 3.950594489675763e-05,
      "loss": 1.4619,
      "step": 177
    },
    {
      "epoch": 0.5696,
      "grad_norm": 0.23971949517726898,
      "learning_rate": 3.901423845438916e-05,
      "loss": 1.5398,
      "step": 178
    },
    {
      "epoch": 0.5728,
      "grad_norm": 0.2568548023700714,
      "learning_rate": 3.852364583726324e-05,
      "loss": 1.4302,
      "step": 179
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.24254627525806427,
      "learning_rate": 3.803421678562213e-05,
      "loss": 1.5006,
      "step": 180
    },
    {
      "epoch": 0.5792,
      "grad_norm": 0.2345292568206787,
      "learning_rate": 3.754600092173641e-05,
      "loss": 1.4628,
      "step": 181
    },
    {
      "epoch": 0.5824,
      "grad_norm": 0.23642884194850922,
      "learning_rate": 3.705904774487396e-05,
      "loss": 1.5579,
      "step": 182
    },
    {
      "epoch": 0.5856,
      "grad_norm": 0.24760553240776062,
      "learning_rate": 3.657340662628116e-05,
      "loss": 1.4191,
      "step": 183
    },
    {
      "epoch": 0.5888,
      "grad_norm": 0.24353325366973877,
      "learning_rate": 3.608912680417737e-05,
      "loss": 1.4405,
      "step": 184
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.2487252801656723,
      "learning_rate": 3.5606257378762696e-05,
      "loss": 1.5142,
      "step": 185
    },
    {
      "epoch": 0.5952,
      "grad_norm": 0.2462477833032608,
      "learning_rate": 3.512484730723986e-05,
      "loss": 1.4443,
      "step": 186
    },
    {
      "epoch": 0.5984,
      "grad_norm": 0.2485497146844864,
      "learning_rate": 3.464494539885047e-05,
      "loss": 1.4098,
      "step": 187
    },
    {
      "epoch": 0.6016,
      "grad_norm": 0.23817312717437744,
      "learning_rate": 3.4166600309926387e-05,
      "loss": 1.4945,
      "step": 188
    },
    {
      "epoch": 0.6048,
      "grad_norm": 0.250163733959198,
      "learning_rate": 3.368986053895655e-05,
      "loss": 1.475,
      "step": 189
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.2440585345029831,
      "learning_rate": 3.3214774421669774e-05,
      "loss": 1.378,
      "step": 190
    },
    {
      "epoch": 0.6112,
      "grad_norm": 0.2350592166185379,
      "learning_rate": 3.2741390126134106e-05,
      "loss": 1.4127,
      "step": 191
    },
    {
      "epoch": 0.6144,
      "grad_norm": 0.25031834840774536,
      "learning_rate": 3.226975564787322e-05,
      "loss": 1.4699,
      "step": 192
    },
    {
      "epoch": 0.6176,
      "grad_norm": 0.24158351123332977,
      "learning_rate": 3.179991880500009e-05,
      "loss": 1.387,
      "step": 193
    },
    {
      "epoch": 0.6208,
      "grad_norm": 0.24606828391551971,
      "learning_rate": 3.133192723336895e-05,
      "loss": 1.4859,
      "step": 194
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.25622713565826416,
      "learning_rate": 3.086582838174551e-05,
      "loss": 1.4925,
      "step": 195
    },
    {
      "epoch": 0.6272,
      "grad_norm": 0.23670299351215363,
      "learning_rate": 3.0401669506996256e-05,
      "loss": 1.5024,
      "step": 196
    },
    {
      "epoch": 0.6304,
      "grad_norm": 0.25742918252944946,
      "learning_rate": 2.9939497669297112e-05,
      "loss": 1.53,
      "step": 197
    },
    {
      "epoch": 0.6336,
      "grad_norm": 0.24776972830295563,
      "learning_rate": 2.9479359727362173e-05,
      "loss": 1.4881,
      "step": 198
    },
    {
      "epoch": 0.6368,
      "grad_norm": 0.24491022527217865,
      "learning_rate": 2.9021302333692734e-05,
      "loss": 1.5192,
      "step": 199
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.2588517665863037,
      "learning_rate": 2.8565371929847284e-05,
      "loss": 1.5243,
      "step": 200
    },
    {
      "epoch": 0.64,
      "eval_loss": 1.4843626022338867,
      "eval_runtime": 7.95,
      "eval_samples_per_second": 23.522,
      "eval_steps_per_second": 3.019,
      "step": 200
    }
  ],
  "logging_steps": 1,
  "max_steps": 312,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.1976281188171776e+17,
  "train_batch_size": 12,
  "trial_name": null,
  "trial_params": null
}
